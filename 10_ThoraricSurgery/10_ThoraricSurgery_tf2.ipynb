{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 폐암 수술 환자의 생존율 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "    0   1     2     3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
      "0  293   1  3.80  2.80   0   0   0   0   0   0  12   0   0   0   1   0  62   0\n",
      "1    1   2  2.88  2.16   1   0   0   0   1   1  14   0   0   0   1   0  60   0\n",
      "2    8   2  3.19  2.50   1   0   0   0   1   0  11   0   0   1   1   0  66   1\n",
      "3   14   2  3.98  3.06   2   0   0   0   1   1  14   0   0   0   1   0  80   1\n",
      "4   17   2  2.21  1.88   0   0   1   0   0   0  12   0   0   0   1   0  56   0\n",
      "     0  1     2     3  4  5  6  7  8  9  10  11  12  13  14  15  16  class\n",
      "0  293  1  3.80  2.80  0  0  0  0  0  0  12   0   0   0   1   0  62      0\n",
      "1    1  2  2.88  2.16  1  0  0  0  1  1  14   0   0   0   1   0  60      0\n",
      "2    8  2  3.19  2.50  1  0  0  0  1  0  11   0   0   1   1   0  66      1\n",
      "3   14  2  3.98  3.06  2  0  0  0  1  1  14   0   0   0   1   0  80      1\n",
      "4   17  2  2.21  1.88  0  0  1  0  0  0  12   0   0   0   1   0  56      0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 딥러닝을 구동하는 데 필요한 케라스 함수 호출\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "print(tf.__version__)\n",
    "\n",
    "# 필요한 라이브러리 불러옴\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "'''\n",
    "# 준비된 수술 환자 데이터를 불러옴\n",
    "Data_set = np.loadtxt(\"../dataset/ThoraricSurgery.csv\", delimiter=',')\n",
    "\n",
    "# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
    "X = Data_set[:, 0:17]\n",
    "Y = Data_set[:, 17]\n",
    "'''\n",
    "\n",
    "# 준비된 수술 환자 데이터를 불러옴 by using pandas\n",
    "#df = pd.read_csv(\"../dataset/ThoraricSurgery.csv\",\n",
    "#                      names=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"class\"])\n",
    "df = pd.read_csv(\"../dataset/ThoraricSurgery.csv\", header=None)\n",
    "print(df.head())\n",
    "df.rename(columns={17:\"class\"}, inplace=True)\n",
    "print(df.head())\n",
    "\n",
    "# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
    "X = df.drop(['class'], axis=1, inplace=False).values\n",
    "Y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# 딥러닝 구조를 결정(모델을 설정하고 실행하는 부분)\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=17, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 딥러닝 실행\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "'''\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        #tf.keras.layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "        tf.keras.layers.Dense(30, input_dim=17, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),        \n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.0005)\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),   # 'mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy', 'mae', 'mse'])\n",
    "    '''\n",
    "    from_logits\tWhether to interpret y_pred as a tensor of logit values. \n",
    "    By default(False), we assume that y_pred contains probabilities (i.e., values in [0, 1]). **Note - Using from_logits=True may be more numerically stable.\n",
    "    '''\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "'''\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 모델의 가중치를 저장하는 콜백 만들기\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "'''\n",
    "\n",
    "# 파일 이름에 에포크 번호를 포함시킵니다(`str.format` 포맷)\n",
    "checkpoint_path = \"training_tf/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "\n",
    "# 열 번째 에포크마다 가중치를 저장하기 위한 콜백을 만듭니다\n",
    "\n",
    "\n",
    "\n",
    "cp_callback = [\n",
    "  #  tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50, baseline=0.4),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        monitor='val_loss',\n",
    "       # mode='min',        \n",
    "        verbose=1, # verbosity mode, 0 or 1.\n",
    "       # save_best_only=True,\n",
    "        save_weights_only=True,    \n",
    "        #save_freq='epoch',\n",
    "        period=50)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 30)                540       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 376 samples, validate on 94 samples\n",
      "Epoch 1/300\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 105.1700 - accuracy: 0.1436 - mae: 0.8564 - mse: 0.8564 - val_loss: 141.2532 - val_accuracy: 0.1702 - val_mae: 0.8298 - val_mse: 0.8298\n",
      "Epoch 2/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 98.2968 - accuracy: 0.1436 - mae: 0.8564 - mse: 0.8564 - val_loss: 134.1201 - val_accuracy: 0.1702 - val_mae: 0.8297 - val_mse: 0.8296\n",
      "Epoch 3/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 93.1814 - accuracy: 0.1436 - mae: 0.8563 - mse: 0.8562 - val_loss: 127.9320 - val_accuracy: 0.1702 - val_mae: 0.8285 - val_mse: 0.8274\n",
      "Epoch 4/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 88.5555 - accuracy: 0.1436 - mae: 0.8559 - mse: 0.8554 - val_loss: 122.1081 - val_accuracy: 0.1809 - val_mae: 0.8230 - val_mse: 0.8205\n",
      "Epoch 5/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 84.1516 - accuracy: 0.1436 - mae: 0.8539 - mse: 0.8520 - val_loss: 116.4938 - val_accuracy: 0.1809 - val_mae: 0.8196 - val_mse: 0.8192\n",
      "Epoch 6/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 79.9039 - accuracy: 0.1489 - mae: 0.8510 - mse: 0.8472 - val_loss: 111.0590 - val_accuracy: 0.1809 - val_mae: 0.8192 - val_mse: 0.8191\n",
      "Epoch 7/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 75.7588 - accuracy: 0.1543 - mae: 0.8461 - mse: 0.8400 - val_loss: 105.7197 - val_accuracy: 0.1809 - val_mae: 0.8190 - val_mse: 0.8186\n",
      "Epoch 8/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 71.6719 - accuracy: 0.1543 - mae: 0.8429 - mse: 0.8347 - val_loss: 100.3915 - val_accuracy: 0.1809 - val_mae: 0.8184 - val_mse: 0.8166\n",
      "Epoch 9/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 67.6564 - accuracy: 0.1622 - mae: 0.8356 - mse: 0.8260 - val_loss: 95.1705 - val_accuracy: 0.1809 - val_mae: 0.8163 - val_mse: 0.8103\n",
      "Epoch 10/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 63.7065 - accuracy: 0.1755 - mae: 0.8225 - mse: 0.8115 - val_loss: 90.0021 - val_accuracy: 0.1809 - val_mae: 0.8120 - val_mse: 0.8020\n",
      "Epoch 11/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 59.8493 - accuracy: 0.1888 - mae: 0.8094 - mse: 0.7986 - val_loss: 85.0144 - val_accuracy: 0.2021 - val_mae: 0.8066 - val_mse: 0.7952\n",
      "Epoch 12/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 56.0884 - accuracy: 0.2074 - mae: 0.7925 - mse: 0.7792 - val_loss: 80.0942 - val_accuracy: 0.1915 - val_mae: 0.8014 - val_mse: 0.7877\n",
      "Epoch 13/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 52.3942 - accuracy: 0.2314 - mae: 0.7745 - mse: 0.7630 - val_loss: 75.1951 - val_accuracy: 0.2128 - val_mae: 0.7928 - val_mse: 0.7830\n",
      "Epoch 14/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 48.7551 - accuracy: 0.2394 - mae: 0.7612 - mse: 0.7522 - val_loss: 70.4670 - val_accuracy: 0.2128 - val_mae: 0.7897 - val_mse: 0.7825\n",
      "Epoch 15/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 45.1841 - accuracy: 0.2500 - mae: 0.7523 - mse: 0.7445 - val_loss: 65.7272 - val_accuracy: 0.2128 - val_mae: 0.7830 - val_mse: 0.7741\n",
      "Epoch 16/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 41.6669 - accuracy: 0.2660 - mae: 0.7394 - mse: 0.7312 - val_loss: 61.1318 - val_accuracy: 0.2234 - val_mae: 0.7695 - val_mse: 0.7604\n",
      "Epoch 17/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 38.1749 - accuracy: 0.2713 - mae: 0.7274 - mse: 0.7189 - val_loss: 56.4754 - val_accuracy: 0.2553 - val_mae: 0.7556 - val_mse: 0.7473\n",
      "Epoch 18/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 34.6823 - accuracy: 0.2899 - mae: 0.7129 - mse: 0.7037 - val_loss: 51.8194 - val_accuracy: 0.2447 - val_mae: 0.7540 - val_mse: 0.7498\n",
      "Epoch 19/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 31.2171 - accuracy: 0.2926 - mae: 0.7021 - mse: 0.6940 - val_loss: 47.2297 - val_accuracy: 0.2447 - val_mae: 0.7507 - val_mse: 0.7421\n",
      "Epoch 20/300\n",
      "376/376 [==============================] - 0s 106us/sample - loss: 27.8375 - accuracy: 0.3112 - mae: 0.6865 - mse: 0.6787 - val_loss: 42.7031 - val_accuracy: 0.2553 - val_mae: 0.7449 - val_mse: 0.7382\n",
      "Epoch 21/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 24.5527 - accuracy: 0.3324 - mae: 0.6694 - mse: 0.6602 - val_loss: 38.2615 - val_accuracy: 0.2553 - val_mae: 0.7402 - val_mse: 0.7343\n",
      "Epoch 22/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 21.3772 - accuracy: 0.3511 - mae: 0.6491 - mse: 0.6396 - val_loss: 33.9215 - val_accuracy: 0.2660 - val_mae: 0.7395 - val_mse: 0.7353\n",
      "Epoch 23/300\n",
      "376/376 [==============================] - 0s 106us/sample - loss: 18.2901 - accuracy: 0.3723 - mae: 0.6228 - mse: 0.6106 - val_loss: 29.5901 - val_accuracy: 0.2447 - val_mae: 0.7496 - val_mse: 0.7461\n",
      "Epoch 24/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 15.3472 - accuracy: 0.4069 - mae: 0.5964 - mse: 0.5869 - val_loss: 25.3868 - val_accuracy: 0.2447 - val_mae: 0.7541 - val_mse: 0.7530\n",
      "Epoch 25/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 12.5534 - accuracy: 0.4282 - mae: 0.5725 - mse: 0.5597 - val_loss: 21.2492 - val_accuracy: 0.2660 - val_mae: 0.7343 - val_mse: 0.7238\n",
      "Epoch 26/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 10.0134 - accuracy: 0.4734 - mae: 0.5268 - mse: 0.5119 - val_loss: 17.5209 - val_accuracy: 0.2979 - val_mae: 0.7020 - val_mse: 0.6954\n",
      "Epoch 27/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 7.7867 - accuracy: 0.5027 - mae: 0.4984 - mse: 0.4795 - val_loss: 13.9396 - val_accuracy: 0.3298 - val_mae: 0.6665 - val_mse: 0.6515\n",
      "Epoch 28/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 5.9730 - accuracy: 0.5638 - mae: 0.4445 - mse: 0.4247 - val_loss: 11.0715 - val_accuracy: 0.3830 - val_mae: 0.6272 - val_mse: 0.6154\n",
      "Epoch 29/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 4.5861 - accuracy: 0.6064 - mae: 0.3900 - mse: 0.3705 - val_loss: 8.5244 - val_accuracy: 0.4043 - val_mae: 0.5967 - val_mse: 0.5789\n",
      "Epoch 30/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 3.5649 - accuracy: 0.6569 - mae: 0.3441 - mse: 0.3273 - val_loss: 6.5641 - val_accuracy: 0.4681 - val_mae: 0.5339 - val_mse: 0.5197\n",
      "Epoch 31/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 2.9120 - accuracy: 0.6995 - mae: 0.3030 - mse: 0.2864 - val_loss: 5.1615 - val_accuracy: 0.5213 - val_mae: 0.4894 - val_mse: 0.4727\n",
      "Epoch 32/300\n",
      "376/376 [==============================] - 0s 106us/sample - loss: 2.5417 - accuracy: 0.7314 - mae: 0.2651 - mse: 0.2466 - val_loss: 4.1182 - val_accuracy: 0.5638 - val_mae: 0.4333 - val_mse: 0.4034\n",
      "Epoch 33/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 2.3682 - accuracy: 0.7793 - mae: 0.2270 - mse: 0.2073 - val_loss: 3.7060 - val_accuracy: 0.5957 - val_mae: 0.3962 - val_mse: 0.3635\n",
      "Epoch 34/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 2.3016 - accuracy: 0.7872 - mae: 0.2097 - mse: 0.1901 - val_loss: 3.5510 - val_accuracy: 0.6064 - val_mae: 0.3884 - val_mse: 0.3555\n",
      "Epoch 35/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 2.2381 - accuracy: 0.7899 - mae: 0.2101 - mse: 0.1900 - val_loss: 3.3527 - val_accuracy: 0.6170 - val_mae: 0.3736 - val_mse: 0.3415\n",
      "Epoch 36/300\n",
      "376/376 [==============================] - 0s 106us/sample - loss: 2.1656 - accuracy: 0.7926 - mae: 0.2067 - mse: 0.1868 - val_loss: 3.1900 - val_accuracy: 0.6489 - val_mae: 0.3642 - val_mse: 0.3326\n",
      "Epoch 37/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 2.0987 - accuracy: 0.7899 - mae: 0.2102 - mse: 0.1903 - val_loss: 2.9365 - val_accuracy: 0.6702 - val_mae: 0.3365 - val_mse: 0.3073\n",
      "Epoch 38/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 2.0286 - accuracy: 0.7979 - mae: 0.2037 - mse: 0.1843 - val_loss: 2.7835 - val_accuracy: 0.6702 - val_mae: 0.3257 - val_mse: 0.2961\n",
      "Epoch 39/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 1.9627 - accuracy: 0.8112 - mae: 0.1977 - mse: 0.1787 - val_loss: 2.7775 - val_accuracy: 0.6596 - val_mae: 0.3501 - val_mse: 0.3180\n",
      "Epoch 40/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 1.8742 - accuracy: 0.8112 - mae: 0.1902 - mse: 0.1690 - val_loss: 3.1375 - val_accuracy: 0.5638 - val_mae: 0.4282 - val_mse: 0.3934\n",
      "Epoch 41/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 1.8041 - accuracy: 0.7872 - mae: 0.2153 - mse: 0.1918 - val_loss: 2.5239 - val_accuracy: 0.6596 - val_mae: 0.3477 - val_mse: 0.3140\n",
      "Epoch 42/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 1.7592 - accuracy: 0.8085 - mae: 0.1982 - mse: 0.1750 - val_loss: 2.6322 - val_accuracy: 0.6064 - val_mae: 0.3928 - val_mse: 0.3544\n",
      "Epoch 43/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 1.6547 - accuracy: 0.8059 - mae: 0.1995 - mse: 0.1760 - val_loss: 2.6415 - val_accuracy: 0.5851 - val_mae: 0.4146 - val_mse: 0.3758\n",
      "Epoch 44/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 1.5916 - accuracy: 0.7846 - mae: 0.2174 - mse: 0.1894 - val_loss: 2.1608 - val_accuracy: 0.6702 - val_mae: 0.3451 - val_mse: 0.3079\n",
      "Epoch 45/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 1.5310 - accuracy: 0.8032 - mae: 0.2009 - mse: 0.1700 - val_loss: 2.2753 - val_accuracy: 0.6064 - val_mae: 0.3945 - val_mse: 0.3511\n",
      "Epoch 46/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 1.5005 - accuracy: 0.7846 - mae: 0.2170 - mse: 0.1816 - val_loss: 2.1218 - val_accuracy: 0.6064 - val_mae: 0.3843 - val_mse: 0.3384\n",
      "Epoch 47/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 1.4499 - accuracy: 0.7899 - mae: 0.2224 - mse: 0.1834 - val_loss: 1.8807 - val_accuracy: 0.6702 - val_mae: 0.3474 - val_mse: 0.3019\n",
      "Epoch 48/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 1.4063 - accuracy: 0.7979 - mae: 0.2189 - mse: 0.1793 - val_loss: 1.7730 - val_accuracy: 0.6702 - val_mae: 0.3407 - val_mse: 0.2926\n",
      "Epoch 49/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 1.3779 - accuracy: 0.7846 - mae: 0.2234 - mse: 0.1805 - val_loss: 1.6256 - val_accuracy: 0.6809 - val_mae: 0.3132 - val_mse: 0.2637\n",
      "Epoch 50/300\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.9402 - accuracy: 0.8906 - mae: 0.1257 - mse: 0.0992\n",
      "Epoch 00050: saving model to training_tf/cp-0050.ckpt\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 1.3487 - accuracy: 0.7979 - mae: 0.2145 - mse: 0.1711 - val_loss: 1.7881 - val_accuracy: 0.6383 - val_mae: 0.3783 - val_mse: 0.3226\n",
      "Epoch 51/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 1.3144 - accuracy: 0.7819 - mae: 0.2271 - mse: 0.1831 - val_loss: 1.6296 - val_accuracy: 0.6702 - val_mae: 0.3557 - val_mse: 0.2990\n",
      "Epoch 52/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 1.2791 - accuracy: 0.7952 - mae: 0.2216 - mse: 0.1779 - val_loss: 1.6441 - val_accuracy: 0.6383 - val_mae: 0.3776 - val_mse: 0.3159\n",
      "Epoch 53/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 1.2648 - accuracy: 0.7899 - mae: 0.2293 - mse: 0.1821 - val_loss: 1.6339 - val_accuracy: 0.6170 - val_mae: 0.3858 - val_mse: 0.3219\n",
      "Epoch 54/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 1.2115 - accuracy: 0.7872 - mae: 0.2301 - mse: 0.1793 - val_loss: 1.4788 - val_accuracy: 0.6596 - val_mae: 0.3594 - val_mse: 0.2947\n",
      "Epoch 55/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 1.2128 - accuracy: 0.8032 - mae: 0.2217 - mse: 0.1742 - val_loss: 1.6865 - val_accuracy: 0.5532 - val_mae: 0.4220 - val_mse: 0.3509\n",
      "Epoch 56/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 1.1690 - accuracy: 0.7793 - mae: 0.2398 - mse: 0.1871 - val_loss: 1.4289 - val_accuracy: 0.6383 - val_mae: 0.3705 - val_mse: 0.2999\n",
      "Epoch 57/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 1.1245 - accuracy: 0.7872 - mae: 0.2348 - mse: 0.1793 - val_loss: 1.2883 - val_accuracy: 0.6596 - val_mae: 0.3363 - val_mse: 0.2670\n",
      "Epoch 58/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 1.0873 - accuracy: 0.7926 - mae: 0.2254 - mse: 0.1710 - val_loss: 1.3256 - val_accuracy: 0.6596 - val_mae: 0.3671 - val_mse: 0.2911\n",
      "Epoch 59/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 1.0640 - accuracy: 0.7713 - mae: 0.2418 - mse: 0.1810 - val_loss: 1.2505 - val_accuracy: 0.6596 - val_mae: 0.3543 - val_mse: 0.2777\n",
      "Epoch 60/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 1.0142 - accuracy: 0.8059 - mae: 0.2265 - mse: 0.1683 - val_loss: 1.3541 - val_accuracy: 0.5957 - val_mae: 0.4001 - val_mse: 0.3165\n",
      "Epoch 61/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.9768 - accuracy: 0.7872 - mae: 0.2396 - mse: 0.1787 - val_loss: 1.1720 - val_accuracy: 0.6596 - val_mae: 0.3655 - val_mse: 0.2806\n",
      "Epoch 62/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.9237 - accuracy: 0.7926 - mae: 0.2332 - mse: 0.1690 - val_loss: 1.4330 - val_accuracy: 0.5532 - val_mae: 0.4411 - val_mse: 0.3536\n",
      "Epoch 63/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 0.8911 - accuracy: 0.7899 - mae: 0.2413 - mse: 0.1761 - val_loss: 1.2499 - val_accuracy: 0.5745 - val_mae: 0.4146 - val_mse: 0.3230\n",
      "Epoch 64/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.8685 - accuracy: 0.7926 - mae: 0.2366 - mse: 0.1717 - val_loss: 1.3417 - val_accuracy: 0.5319 - val_mae: 0.4453 - val_mse: 0.3523\n",
      "Epoch 65/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.8340 - accuracy: 0.7846 - mae: 0.2496 - mse: 0.1806 - val_loss: 0.9731 - val_accuracy: 0.6489 - val_mae: 0.3575 - val_mse: 0.2650\n",
      "Epoch 66/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.7797 - accuracy: 0.7979 - mae: 0.2367 - mse: 0.1654 - val_loss: 0.9738 - val_accuracy: 0.6383 - val_mae: 0.3752 - val_mse: 0.2772\n",
      "Epoch 67/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.7298 - accuracy: 0.7926 - mae: 0.2432 - mse: 0.1677 - val_loss: 0.8936 - val_accuracy: 0.6489 - val_mae: 0.3576 - val_mse: 0.2589\n",
      "Epoch 68/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.6866 - accuracy: 0.7926 - mae: 0.2382 - mse: 0.1626 - val_loss: 0.8183 - val_accuracy: 0.6489 - val_mae: 0.3433 - val_mse: 0.2413\n",
      "Epoch 69/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.6572 - accuracy: 0.7979 - mae: 0.2370 - mse: 0.1589 - val_loss: 0.8088 - val_accuracy: 0.6383 - val_mae: 0.3645 - val_mse: 0.2482\n",
      "Epoch 70/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.6277 - accuracy: 0.8059 - mae: 0.2438 - mse: 0.1584 - val_loss: 0.7325 - val_accuracy: 0.6809 - val_mae: 0.3484 - val_mse: 0.2270\n",
      "Epoch 71/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.6053 - accuracy: 0.8191 - mae: 0.2388 - mse: 0.1526 - val_loss: 0.7857 - val_accuracy: 0.6064 - val_mae: 0.3936 - val_mse: 0.2547\n",
      "Epoch 72/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.5959 - accuracy: 0.8298 - mae: 0.2391 - mse: 0.1506 - val_loss: 0.6743 - val_accuracy: 0.6915 - val_mae: 0.3515 - val_mse: 0.2148\n",
      "Epoch 73/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.5787 - accuracy: 0.8191 - mae: 0.2440 - mse: 0.1529 - val_loss: 0.6110 - val_accuracy: 0.7553 - val_mae: 0.3163 - val_mse: 0.1893\n",
      "Epoch 74/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.5620 - accuracy: 0.8245 - mae: 0.2463 - mse: 0.1494 - val_loss: 0.5528 - val_accuracy: 0.7979 - val_mae: 0.2527 - val_mse: 0.1599\n",
      "Epoch 75/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.5543 - accuracy: 0.8351 - mae: 0.2304 - mse: 0.1454 - val_loss: 0.7248 - val_accuracy: 0.6064 - val_mae: 0.4098 - val_mse: 0.2482\n",
      "Epoch 76/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.5326 - accuracy: 0.8218 - mae: 0.2495 - mse: 0.1460 - val_loss: 0.5220 - val_accuracy: 0.8085 - val_mae: 0.2430 - val_mse: 0.1535\n",
      "Epoch 77/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.5290 - accuracy: 0.8378 - mae: 0.2323 - mse: 0.1420 - val_loss: 0.6435 - val_accuracy: 0.6596 - val_mae: 0.3843 - val_mse: 0.2190\n",
      "Epoch 78/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.5286 - accuracy: 0.8457 - mae: 0.2452 - mse: 0.1430 - val_loss: 0.5138 - val_accuracy: 0.7979 - val_mae: 0.2878 - val_mse: 0.1610\n",
      "Epoch 79/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.5173 - accuracy: 0.8351 - mae: 0.2408 - mse: 0.1424 - val_loss: 0.5035 - val_accuracy: 0.7979 - val_mae: 0.2899 - val_mse: 0.1590\n",
      "Epoch 80/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.5110 - accuracy: 0.8484 - mae: 0.2468 - mse: 0.1418 - val_loss: 0.4875 - val_accuracy: 0.8298 - val_mae: 0.2281 - val_mse: 0.1468\n",
      "Epoch 81/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.5273 - accuracy: 0.8271 - mae: 0.2440 - mse: 0.1470 - val_loss: 0.4831 - val_accuracy: 0.8085 - val_mae: 0.2755 - val_mse: 0.1522\n",
      "Epoch 82/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4904 - accuracy: 0.8511 - mae: 0.2411 - mse: 0.1366 - val_loss: 0.4721 - val_accuracy: 0.8085 - val_mae: 0.2605 - val_mse: 0.1479\n",
      "Epoch 83/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4969 - accuracy: 0.8431 - mae: 0.2358 - mse: 0.1381 - val_loss: 0.5971 - val_accuracy: 0.7128 - val_mae: 0.3867 - val_mse: 0.2061\n",
      "Epoch 84/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.5082 - accuracy: 0.8431 - mae: 0.2483 - mse: 0.1411 - val_loss: 0.5011 - val_accuracy: 0.7979 - val_mae: 0.3207 - val_mse: 0.1633\n",
      "Epoch 85/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4746 - accuracy: 0.8511 - mae: 0.2390 - mse: 0.1333 - val_loss: 0.5253 - val_accuracy: 0.7979 - val_mae: 0.3484 - val_mse: 0.1748\n",
      "Epoch 86/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4976 - accuracy: 0.8457 - mae: 0.2539 - mse: 0.1398 - val_loss: 0.4554 - val_accuracy: 0.8085 - val_mae: 0.2651 - val_mse: 0.1445\n",
      "Epoch 87/300\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.4715 - accuracy: 0.8511 - mae: 0.2387 - mse: 0.1339 - val_loss: 0.4943 - val_accuracy: 0.7979 - val_mae: 0.3228 - val_mse: 0.1613\n",
      "Epoch 88/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4666 - accuracy: 0.8537 - mae: 0.2461 - mse: 0.1325 - val_loss: 0.4492 - val_accuracy: 0.8191 - val_mae: 0.2565 - val_mse: 0.1425\n",
      "Epoch 89/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4801 - accuracy: 0.8537 - mae: 0.2360 - mse: 0.1350 - val_loss: 0.4615 - val_accuracy: 0.8085 - val_mae: 0.2961 - val_mse: 0.1483\n",
      "Epoch 90/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4735 - accuracy: 0.8484 - mae: 0.2441 - mse: 0.1351 - val_loss: 0.5021 - val_accuracy: 0.7766 - val_mae: 0.3387 - val_mse: 0.1654\n",
      "Epoch 91/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4837 - accuracy: 0.8537 - mae: 0.2420 - mse: 0.1365 - val_loss: 0.5187 - val_accuracy: 0.7766 - val_mae: 0.3559 - val_mse: 0.1729\n",
      "Epoch 92/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4793 - accuracy: 0.8484 - mae: 0.2500 - mse: 0.1371 - val_loss: 0.4709 - val_accuracy: 0.8085 - val_mae: 0.3152 - val_mse: 0.1526\n",
      "Epoch 93/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4734 - accuracy: 0.8564 - mae: 0.2521 - mse: 0.1356 - val_loss: 0.4394 - val_accuracy: 0.8298 - val_mae: 0.2607 - val_mse: 0.1404\n",
      "Epoch 94/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4485 - accuracy: 0.8537 - mae: 0.2371 - mse: 0.1289 - val_loss: 0.4475 - val_accuracy: 0.7979 - val_mae: 0.2857 - val_mse: 0.1438\n",
      "Epoch 95/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4723 - accuracy: 0.8484 - mae: 0.2429 - mse: 0.1334 - val_loss: 0.4362 - val_accuracy: 0.8191 - val_mae: 0.2463 - val_mse: 0.1399\n",
      "Epoch 96/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4619 - accuracy: 0.8484 - mae: 0.2441 - mse: 0.1346 - val_loss: 0.4427 - val_accuracy: 0.8191 - val_mae: 0.2345 - val_mse: 0.1416\n",
      "Epoch 97/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4588 - accuracy: 0.8537 - mae: 0.2387 - mse: 0.1321 - val_loss: 0.4617 - val_accuracy: 0.7979 - val_mae: 0.3028 - val_mse: 0.1496\n",
      "Epoch 98/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4457 - accuracy: 0.8537 - mae: 0.2428 - mse: 0.1284 - val_loss: 0.4385 - val_accuracy: 0.8191 - val_mae: 0.2555 - val_mse: 0.1417\n",
      "Epoch 99/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4457 - accuracy: 0.8537 - mae: 0.2428 - mse: 0.1307 - val_loss: 0.4541 - val_accuracy: 0.8085 - val_mae: 0.2899 - val_mse: 0.1469\n",
      "Epoch 100/300\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.4904 - accuracy: 0.8281 - mae: 0.2673 - mse: 0.1478\n",
      "Epoch 00100: saving model to training_tf/cp-0100.ckpt\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 0.4722 - accuracy: 0.8484 - mae: 0.2459 - mse: 0.1358 - val_loss: 0.4628 - val_accuracy: 0.7979 - val_mae: 0.3016 - val_mse: 0.1497\n",
      "Epoch 101/300\n",
      "376/376 [==============================] - 0s 109us/sample - loss: 0.4533 - accuracy: 0.8537 - mae: 0.2497 - mse: 0.1316 - val_loss: 0.4479 - val_accuracy: 0.8191 - val_mae: 0.2465 - val_mse: 0.1444\n",
      "Epoch 102/300\n",
      "376/376 [==============================] - 0s 106us/sample - loss: 0.4568 - accuracy: 0.8537 - mae: 0.2413 - mse: 0.1328 - val_loss: 0.4492 - val_accuracy: 0.8191 - val_mae: 0.2707 - val_mse: 0.1443\n",
      "Epoch 103/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4459 - accuracy: 0.8537 - mae: 0.2400 - mse: 0.1301 - val_loss: 0.5022 - val_accuracy: 0.7979 - val_mae: 0.3394 - val_mse: 0.1627\n",
      "Epoch 104/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4532 - accuracy: 0.8457 - mae: 0.2553 - mse: 0.1341 - val_loss: 0.4559 - val_accuracy: 0.8191 - val_mae: 0.2386 - val_mse: 0.1456\n",
      "Epoch 105/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.4498 - accuracy: 0.8537 - mae: 0.2440 - mse: 0.1310 - val_loss: 0.4583 - val_accuracy: 0.8191 - val_mae: 0.2390 - val_mse: 0.1461\n",
      "Epoch 106/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4318 - accuracy: 0.8537 - mae: 0.2372 - mse: 0.1277 - val_loss: 0.4646 - val_accuracy: 0.8191 - val_mae: 0.2883 - val_mse: 0.1471\n",
      "Epoch 107/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.4560 - accuracy: 0.8564 - mae: 0.2491 - mse: 0.1329 - val_loss: 0.4593 - val_accuracy: 0.8191 - val_mae: 0.2431 - val_mse: 0.1457\n",
      "Epoch 108/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4488 - accuracy: 0.8537 - mae: 0.2467 - mse: 0.1327 - val_loss: 0.4663 - val_accuracy: 0.8191 - val_mae: 0.2346 - val_mse: 0.1473\n",
      "Epoch 109/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4347 - accuracy: 0.8537 - mae: 0.2321 - mse: 0.1255 - val_loss: 0.4634 - val_accuracy: 0.8191 - val_mae: 0.2746 - val_mse: 0.1456\n",
      "Epoch 110/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4361 - accuracy: 0.8511 - mae: 0.2504 - mse: 0.1290 - val_loss: 0.4655 - val_accuracy: 0.8191 - val_mae: 0.2537 - val_mse: 0.1470\n",
      "Epoch 111/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4549 - accuracy: 0.8511 - mae: 0.2449 - mse: 0.1337 - val_loss: 0.4662 - val_accuracy: 0.8191 - val_mae: 0.2508 - val_mse: 0.1470\n",
      "Epoch 112/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4446 - accuracy: 0.8537 - mae: 0.2442 - mse: 0.1304 - val_loss: 0.4701 - val_accuracy: 0.8191 - val_mae: 0.2397 - val_mse: 0.1476\n",
      "Epoch 113/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4350 - accuracy: 0.8511 - mae: 0.2410 - mse: 0.1286 - val_loss: 0.4744 - val_accuracy: 0.8191 - val_mae: 0.2333 - val_mse: 0.1481\n",
      "Epoch 114/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 0.4327 - accuracy: 0.8511 - mae: 0.2392 - mse: 0.1277 - val_loss: 0.4714 - val_accuracy: 0.8191 - val_mae: 0.2653 - val_mse: 0.1475\n",
      "Epoch 115/300\n",
      "376/376 [==============================] - 0s 112us/sample - loss: 0.4373 - accuracy: 0.8484 - mae: 0.2378 - mse: 0.1295 - val_loss: 0.4658 - val_accuracy: 0.8191 - val_mae: 0.2582 - val_mse: 0.1451\n",
      "Epoch 116/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.4199 - accuracy: 0.8511 - mae: 0.2376 - mse: 0.1253 - val_loss: 0.5725 - val_accuracy: 0.7766 - val_mae: 0.3778 - val_mse: 0.1859\n",
      "Epoch 117/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4461 - accuracy: 0.8511 - mae: 0.2543 - mse: 0.1334 - val_loss: 0.4719 - val_accuracy: 0.8191 - val_mae: 0.2445 - val_mse: 0.1472\n",
      "Epoch 118/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4243 - accuracy: 0.8511 - mae: 0.2427 - mse: 0.1265 - val_loss: 0.4895 - val_accuracy: 0.8191 - val_mae: 0.2223 - val_mse: 0.1510\n",
      "Epoch 119/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 0.4227 - accuracy: 0.8537 - mae: 0.2315 - mse: 0.1248 - val_loss: 0.5254 - val_accuracy: 0.7979 - val_mae: 0.3371 - val_mse: 0.1659\n",
      "Epoch 120/300\n",
      "376/376 [==============================] - 0s 114us/sample - loss: 0.4522 - accuracy: 0.8511 - mae: 0.2550 - mse: 0.1340 - val_loss: 0.4962 - val_accuracy: 0.8191 - val_mae: 0.2188 - val_mse: 0.1523\n",
      "Epoch 121/300\n",
      "376/376 [==============================] - 0s 130us/sample - loss: 0.4351 - accuracy: 0.8511 - mae: 0.2233 - mse: 0.1273 - val_loss: 0.6662 - val_accuracy: 0.5957 - val_mae: 0.4361 - val_mse: 0.2275\n",
      "Epoch 122/300\n",
      "376/376 [==============================] - 0s 125us/sample - loss: 0.4431 - accuracy: 0.8511 - mae: 0.2611 - mse: 0.1340 - val_loss: 0.4731 - val_accuracy: 0.8191 - val_mae: 0.2579 - val_mse: 0.1478\n",
      "Epoch 123/300\n",
      "376/376 [==============================] - 0s 120us/sample - loss: 0.4249 - accuracy: 0.8537 - mae: 0.2356 - mse: 0.1271 - val_loss: 0.4752 - val_accuracy: 0.8191 - val_mae: 0.2780 - val_mse: 0.1476\n",
      "Epoch 124/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4323 - accuracy: 0.8511 - mae: 0.2491 - mse: 0.1291 - val_loss: 0.4825 - val_accuracy: 0.8191 - val_mae: 0.2310 - val_mse: 0.1499\n",
      "Epoch 125/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4257 - accuracy: 0.8511 - mae: 0.2302 - mse: 0.1265 - val_loss: 0.5710 - val_accuracy: 0.7660 - val_mae: 0.3753 - val_mse: 0.1842\n",
      "Epoch 126/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4213 - accuracy: 0.8537 - mae: 0.2349 - mse: 0.1254 - val_loss: 0.6221 - val_accuracy: 0.7128 - val_mae: 0.4108 - val_mse: 0.2061\n",
      "Epoch 127/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4351 - accuracy: 0.8511 - mae: 0.2557 - mse: 0.1301 - val_loss: 0.4856 - val_accuracy: 0.8191 - val_mae: 0.2260 - val_mse: 0.1496\n",
      "Epoch 128/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4230 - accuracy: 0.8511 - mae: 0.2354 - mse: 0.1259 - val_loss: 0.4993 - val_accuracy: 0.7979 - val_mae: 0.3104 - val_mse: 0.1546\n",
      "Epoch 129/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4351 - accuracy: 0.8511 - mae: 0.2524 - mse: 0.1298 - val_loss: 0.5078 - val_accuracy: 0.8191 - val_mae: 0.2134 - val_mse: 0.1533\n",
      "Epoch 130/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4175 - accuracy: 0.8511 - mae: 0.2242 - mse: 0.1233 - val_loss: 0.6224 - val_accuracy: 0.7234 - val_mae: 0.4098 - val_mse: 0.2053\n",
      "Epoch 131/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4366 - accuracy: 0.8484 - mae: 0.2546 - mse: 0.1289 - val_loss: 0.4864 - val_accuracy: 0.8191 - val_mae: 0.2275 - val_mse: 0.1497\n",
      "Epoch 132/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4209 - accuracy: 0.8511 - mae: 0.2327 - mse: 0.1247 - val_loss: 0.5112 - val_accuracy: 0.7979 - val_mae: 0.3238 - val_mse: 0.1584\n",
      "Epoch 133/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4233 - accuracy: 0.8484 - mae: 0.2442 - mse: 0.1282 - val_loss: 0.4794 - val_accuracy: 0.8191 - val_mae: 0.2824 - val_mse: 0.1479\n",
      "Epoch 134/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4225 - accuracy: 0.8511 - mae: 0.2460 - mse: 0.1268 - val_loss: 0.4743 - val_accuracy: 0.8191 - val_mae: 0.2529 - val_mse: 0.1472\n",
      "Epoch 135/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4386 - accuracy: 0.8511 - mae: 0.2485 - mse: 0.1298 - val_loss: 0.4998 - val_accuracy: 0.8191 - val_mae: 0.2175 - val_mse: 0.1524\n",
      "Epoch 136/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4260 - accuracy: 0.8511 - mae: 0.2328 - mse: 0.1275 - val_loss: 0.4905 - val_accuracy: 0.7979 - val_mae: 0.3000 - val_mse: 0.1512\n",
      "Epoch 137/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4303 - accuracy: 0.8511 - mae: 0.2400 - mse: 0.1283 - val_loss: 0.5228 - val_accuracy: 0.7979 - val_mae: 0.3369 - val_mse: 0.1624\n",
      "Epoch 138/300\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.4138 - accuracy: 0.8537 - mae: 0.2524 - mse: 0.1255 - val_loss: 0.4998 - val_accuracy: 0.8191 - val_mae: 0.2172 - val_mse: 0.1524\n",
      "Epoch 139/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4408 - accuracy: 0.8484 - mae: 0.2509 - mse: 0.1315 - val_loss: 0.5351 - val_accuracy: 0.8191 - val_mae: 0.2045 - val_mse: 0.1573\n",
      "Epoch 140/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4308 - accuracy: 0.8511 - mae: 0.2245 - mse: 0.1263 - val_loss: 0.4761 - val_accuracy: 0.8191 - val_mae: 0.2804 - val_mse: 0.1475\n",
      "Epoch 141/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4460 - accuracy: 0.8457 - mae: 0.2529 - mse: 0.1329 - val_loss: 0.4814 - val_accuracy: 0.8191 - val_mae: 0.2299 - val_mse: 0.1491\n",
      "Epoch 142/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4232 - accuracy: 0.8484 - mae: 0.2380 - mse: 0.1260 - val_loss: 0.4736 - val_accuracy: 0.8191 - val_mae: 0.2432 - val_mse: 0.1473\n",
      "Epoch 143/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4320 - accuracy: 0.8511 - mae: 0.2424 - mse: 0.1272 - val_loss: 0.4812 - val_accuracy: 0.8191 - val_mae: 0.2299 - val_mse: 0.1491\n",
      "Epoch 144/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4139 - accuracy: 0.8511 - mae: 0.2393 - mse: 0.1234 - val_loss: 0.4992 - val_accuracy: 0.8191 - val_mae: 0.2177 - val_mse: 0.1528\n",
      "Epoch 145/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4132 - accuracy: 0.8511 - mae: 0.2317 - mse: 0.1237 - val_loss: 0.4721 - val_accuracy: 0.8191 - val_mae: 0.2460 - val_mse: 0.1469\n",
      "Epoch 146/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4286 - accuracy: 0.8511 - mae: 0.2423 - mse: 0.1288 - val_loss: 0.4710 - val_accuracy: 0.8191 - val_mae: 0.2467 - val_mse: 0.1463\n",
      "Epoch 147/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4287 - accuracy: 0.8511 - mae: 0.2401 - mse: 0.1276 - val_loss: 0.4688 - val_accuracy: 0.8191 - val_mae: 0.2527 - val_mse: 0.1457\n",
      "Epoch 148/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4158 - accuracy: 0.8511 - mae: 0.2401 - mse: 0.1237 - val_loss: 0.4762 - val_accuracy: 0.8191 - val_mae: 0.2712 - val_mse: 0.1478\n",
      "Epoch 149/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4248 - accuracy: 0.8511 - mae: 0.2344 - mse: 0.1257 - val_loss: 0.5389 - val_accuracy: 0.7766 - val_mae: 0.3512 - val_mse: 0.1698\n",
      "Epoch 150/300\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.4812 - accuracy: 0.8281 - mae: 0.3223 - mse: 0.1484\n",
      "Epoch 00150: saving model to training_tf/cp-0150.ckpt\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 0.4472 - accuracy: 0.8537 - mae: 0.2569 - mse: 0.1317 - val_loss: 0.4786 - val_accuracy: 0.8191 - val_mae: 0.2404 - val_mse: 0.1491\n",
      "Epoch 151/300\n",
      "376/376 [==============================] - 0s 106us/sample - loss: 0.4168 - accuracy: 0.8511 - mae: 0.2373 - mse: 0.1248 - val_loss: 0.4754 - val_accuracy: 0.8191 - val_mae: 0.2644 - val_mse: 0.1478\n",
      "Epoch 152/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4127 - accuracy: 0.8511 - mae: 0.2374 - mse: 0.1232 - val_loss: 0.4815 - val_accuracy: 0.8085 - val_mae: 0.2859 - val_mse: 0.1491\n",
      "Epoch 153/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 0.4195 - accuracy: 0.8511 - mae: 0.2348 - mse: 0.1238 - val_loss: 0.5140 - val_accuracy: 0.7979 - val_mae: 0.3280 - val_mse: 0.1598\n",
      "Epoch 154/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4276 - accuracy: 0.8511 - mae: 0.2532 - mse: 0.1285 - val_loss: 0.5045 - val_accuracy: 0.8191 - val_mae: 0.2143 - val_mse: 0.1531\n",
      "Epoch 155/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4247 - accuracy: 0.8511 - mae: 0.2352 - mse: 0.1244 - val_loss: 0.4875 - val_accuracy: 0.8191 - val_mae: 0.2243 - val_mse: 0.1502\n",
      "Epoch 156/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4147 - accuracy: 0.8511 - mae: 0.2287 - mse: 0.1240 - val_loss: 0.5931 - val_accuracy: 0.7660 - val_mae: 0.3898 - val_mse: 0.1934\n",
      "Epoch 157/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4178 - accuracy: 0.8511 - mae: 0.2432 - mse: 0.1247 - val_loss: 0.4815 - val_accuracy: 0.8085 - val_mae: 0.2862 - val_mse: 0.1491\n",
      "Epoch 158/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4094 - accuracy: 0.8511 - mae: 0.2376 - mse: 0.1228 - val_loss: 0.5213 - val_accuracy: 0.7979 - val_mae: 0.3341 - val_mse: 0.1631\n",
      "Epoch 159/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4429 - accuracy: 0.8484 - mae: 0.2442 - mse: 0.1307 - val_loss: 0.4778 - val_accuracy: 0.8085 - val_mae: 0.2839 - val_mse: 0.1479\n",
      "Epoch 160/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4060 - accuracy: 0.8511 - mae: 0.2420 - mse: 0.1222 - val_loss: 0.4717 - val_accuracy: 0.8191 - val_mae: 0.2579 - val_mse: 0.1467\n",
      "Epoch 161/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4219 - accuracy: 0.8537 - mae: 0.2443 - mse: 0.1251 - val_loss: 0.5006 - val_accuracy: 0.8191 - val_mae: 0.2163 - val_mse: 0.1529\n",
      "Epoch 162/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4192 - accuracy: 0.8511 - mae: 0.2344 - mse: 0.1235 - val_loss: 0.4823 - val_accuracy: 0.8191 - val_mae: 0.2295 - val_mse: 0.1495\n",
      "Epoch 163/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.4147 - accuracy: 0.8511 - mae: 0.2355 - mse: 0.1234 - val_loss: 0.4737 - val_accuracy: 0.8191 - val_mae: 0.2652 - val_mse: 0.1470\n",
      "Epoch 164/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4317 - accuracy: 0.8537 - mae: 0.2392 - mse: 0.1272 - val_loss: 0.5094 - val_accuracy: 0.7979 - val_mae: 0.3183 - val_mse: 0.1586\n",
      "Epoch 165/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4044 - accuracy: 0.8511 - mae: 0.2325 - mse: 0.1214 - val_loss: 0.5986 - val_accuracy: 0.7660 - val_mae: 0.3919 - val_mse: 0.1953\n",
      "Epoch 166/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4112 - accuracy: 0.8484 - mae: 0.2480 - mse: 0.1235 - val_loss: 0.4872 - val_accuracy: 0.8191 - val_mae: 0.2242 - val_mse: 0.1503\n",
      "Epoch 167/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4221 - accuracy: 0.8511 - mae: 0.2334 - mse: 0.1245 - val_loss: 0.4717 - val_accuracy: 0.8191 - val_mae: 0.2566 - val_mse: 0.1462\n",
      "Epoch 168/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4188 - accuracy: 0.8537 - mae: 0.2416 - mse: 0.1247 - val_loss: 0.4740 - val_accuracy: 0.8191 - val_mae: 0.2549 - val_mse: 0.1473\n",
      "Epoch 169/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4275 - accuracy: 0.8484 - mae: 0.2448 - mse: 0.1308 - val_loss: 0.4730 - val_accuracy: 0.8191 - val_mae: 0.2534 - val_mse: 0.1471\n",
      "Epoch 170/300\n",
      "376/376 [==============================] - 0s 109us/sample - loss: 0.4148 - accuracy: 0.8484 - mae: 0.2374 - mse: 0.1246 - val_loss: 0.4863 - val_accuracy: 0.8085 - val_mae: 0.2898 - val_mse: 0.1509\n",
      "Epoch 171/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.4231 - accuracy: 0.8484 - mae: 0.2526 - mse: 0.1287 - val_loss: 0.5034 - val_accuracy: 0.8191 - val_mae: 0.2145 - val_mse: 0.1533\n",
      "Epoch 172/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4227 - accuracy: 0.8511 - mae: 0.2351 - mse: 0.1261 - val_loss: 0.4771 - val_accuracy: 0.8191 - val_mae: 0.2357 - val_mse: 0.1483\n",
      "Epoch 173/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4122 - accuracy: 0.8537 - mae: 0.2361 - mse: 0.1228 - val_loss: 0.4701 - val_accuracy: 0.8191 - val_mae: 0.2534 - val_mse: 0.1462\n",
      "Epoch 174/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4114 - accuracy: 0.8564 - mae: 0.2450 - mse: 0.1244 - val_loss: 0.4966 - val_accuracy: 0.8191 - val_mae: 0.2178 - val_mse: 0.1521\n",
      "Epoch 175/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4368 - accuracy: 0.8511 - mae: 0.2384 - mse: 0.1290 - val_loss: 0.4737 - val_accuracy: 0.8191 - val_mae: 0.2468 - val_mse: 0.1475\n",
      "Epoch 176/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4418 - accuracy: 0.8511 - mae: 0.2458 - mse: 0.1308 - val_loss: 0.4802 - val_accuracy: 0.8191 - val_mae: 0.2331 - val_mse: 0.1492\n",
      "Epoch 177/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4012 - accuracy: 0.8537 - mae: 0.2292 - mse: 0.1203 - val_loss: 0.4876 - val_accuracy: 0.7979 - val_mae: 0.2934 - val_mse: 0.1511\n",
      "Epoch 178/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4149 - accuracy: 0.8511 - mae: 0.2426 - mse: 0.1239 - val_loss: 0.4695 - val_accuracy: 0.8191 - val_mae: 0.2572 - val_mse: 0.1459\n",
      "Epoch 179/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4267 - accuracy: 0.8511 - mae: 0.2294 - mse: 0.1257 - val_loss: 0.5754 - val_accuracy: 0.7979 - val_mae: 0.3767 - val_mse: 0.1856\n",
      "Epoch 180/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4202 - accuracy: 0.8564 - mae: 0.2535 - mse: 0.1260 - val_loss: 0.4760 - val_accuracy: 0.8191 - val_mae: 0.2373 - val_mse: 0.1483\n",
      "Epoch 181/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4108 - accuracy: 0.8511 - mae: 0.2337 - mse: 0.1225 - val_loss: 0.4700 - val_accuracy: 0.8191 - val_mae: 0.2479 - val_mse: 0.1464\n",
      "Epoch 182/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4023 - accuracy: 0.8511 - mae: 0.2398 - mse: 0.1209 - val_loss: 0.4840 - val_accuracy: 0.8191 - val_mae: 0.2247 - val_mse: 0.1496\n",
      "Epoch 183/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.4102 - accuracy: 0.8537 - mae: 0.2349 - mse: 0.1225 - val_loss: 0.4716 - val_accuracy: 0.8191 - val_mae: 0.2599 - val_mse: 0.1465\n",
      "Epoch 184/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4245 - accuracy: 0.8511 - mae: 0.2433 - mse: 0.1258 - val_loss: 0.4861 - val_accuracy: 0.8191 - val_mae: 0.2259 - val_mse: 0.1502\n",
      "Epoch 185/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4394 - accuracy: 0.8298 - mae: 0.2473 - mse: 0.1327 - val_loss: 0.4953 - val_accuracy: 0.8191 - val_mae: 0.2193 - val_mse: 0.1520\n",
      "Epoch 186/300\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.4090 - accuracy: 0.8564 - mae: 0.2235 - mse: 0.1207 - val_loss: 0.4973 - val_accuracy: 0.7979 - val_mae: 0.3054 - val_mse: 0.1541\n",
      "Epoch 187/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4030 - accuracy: 0.8537 - mae: 0.2452 - mse: 0.1214 - val_loss: 0.4847 - val_accuracy: 0.8191 - val_mae: 0.2286 - val_mse: 0.1501\n",
      "Epoch 188/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4110 - accuracy: 0.8511 - mae: 0.2310 - mse: 0.1219 - val_loss: 0.4723 - val_accuracy: 0.8191 - val_mae: 0.2463 - val_mse: 0.1470\n",
      "Epoch 189/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4097 - accuracy: 0.8511 - mae: 0.2330 - mse: 0.1226 - val_loss: 0.4693 - val_accuracy: 0.8191 - val_mae: 0.2514 - val_mse: 0.1458\n",
      "Epoch 190/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4012 - accuracy: 0.8537 - mae: 0.2356 - mse: 0.1205 - val_loss: 0.4714 - val_accuracy: 0.8191 - val_mae: 0.2710 - val_mse: 0.1460\n",
      "Epoch 191/300\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.4102 - accuracy: 0.8484 - mae: 0.2406 - mse: 0.1232 - val_loss: 0.4739 - val_accuracy: 0.8191 - val_mae: 0.2399 - val_mse: 0.1478\n",
      "Epoch 192/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4101 - accuracy: 0.8511 - mae: 0.2382 - mse: 0.1244 - val_loss: 0.4741 - val_accuracy: 0.8191 - val_mae: 0.2380 - val_mse: 0.1478\n",
      "Epoch 193/300\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.4325 - accuracy: 0.8564 - mae: 0.2433 - mse: 0.1301 - val_loss: 0.4711 - val_accuracy: 0.8191 - val_mae: 0.2641 - val_mse: 0.1471\n",
      "Epoch 194/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.3977 - accuracy: 0.8537 - mae: 0.2426 - mse: 0.1198 - val_loss: 0.4969 - val_accuracy: 0.8191 - val_mae: 0.2173 - val_mse: 0.1527\n",
      "Epoch 195/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4160 - accuracy: 0.8457 - mae: 0.2338 - mse: 0.1257 - val_loss: 0.4711 - val_accuracy: 0.8191 - val_mae: 0.2576 - val_mse: 0.1473\n",
      "Epoch 196/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.3988 - accuracy: 0.8537 - mae: 0.2368 - mse: 0.1196 - val_loss: 0.4696 - val_accuracy: 0.8191 - val_mae: 0.2546 - val_mse: 0.1469\n",
      "Epoch 197/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4126 - accuracy: 0.8564 - mae: 0.2358 - mse: 0.1240 - val_loss: 0.4970 - val_accuracy: 0.7979 - val_mae: 0.3103 - val_mse: 0.1552\n",
      "Epoch 198/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4213 - accuracy: 0.8564 - mae: 0.2426 - mse: 0.1249 - val_loss: 0.4698 - val_accuracy: 0.8191 - val_mae: 0.2634 - val_mse: 0.1465\n",
      "Epoch 199/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4304 - accuracy: 0.8511 - mae: 0.2446 - mse: 0.1265 - val_loss: 0.4808 - val_accuracy: 0.8191 - val_mae: 0.2286 - val_mse: 0.1495\n",
      "Epoch 200/300\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.4770 - accuracy: 0.8125 - mae: 0.2354 - mse: 0.1504\n",
      "Epoch 00200: saving model to training_tf/cp-0200.ckpt\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 0.4060 - accuracy: 0.8511 - mae: 0.2269 - mse: 0.1223 - val_loss: 0.5152 - val_accuracy: 0.7872 - val_mae: 0.3302 - val_mse: 0.1614\n",
      "Epoch 201/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 0.4377 - accuracy: 0.8484 - mae: 0.2481 - mse: 0.1299 - val_loss: 0.4682 - val_accuracy: 0.8191 - val_mae: 0.2640 - val_mse: 0.1458\n",
      "Epoch 202/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4156 - accuracy: 0.8457 - mae: 0.2448 - mse: 0.1255 - val_loss: 0.4851 - val_accuracy: 0.8191 - val_mae: 0.2241 - val_mse: 0.1503\n",
      "Epoch 203/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4057 - accuracy: 0.8564 - mae: 0.2221 - mse: 0.1212 - val_loss: 0.5307 - val_accuracy: 0.7872 - val_mae: 0.3421 - val_mse: 0.1674\n",
      "Epoch 204/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4252 - accuracy: 0.8564 - mae: 0.2528 - mse: 0.1275 - val_loss: 0.4745 - val_accuracy: 0.8191 - val_mae: 0.2444 - val_mse: 0.1479\n",
      "Epoch 205/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4178 - accuracy: 0.8457 - mae: 0.2403 - mse: 0.1272 - val_loss: 0.4732 - val_accuracy: 0.8191 - val_mae: 0.2441 - val_mse: 0.1475\n",
      "Epoch 206/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4074 - accuracy: 0.8537 - mae: 0.2422 - mse: 0.1229 - val_loss: 0.4948 - val_accuracy: 0.8191 - val_mae: 0.2193 - val_mse: 0.1522\n",
      "Epoch 207/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4185 - accuracy: 0.8537 - mae: 0.2282 - mse: 0.1227 - val_loss: 0.4906 - val_accuracy: 0.7979 - val_mae: 0.2969 - val_mse: 0.1524\n",
      "Epoch 208/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.3974 - accuracy: 0.8564 - mae: 0.2371 - mse: 0.1195 - val_loss: 0.4866 - val_accuracy: 0.8085 - val_mae: 0.2854 - val_mse: 0.1515\n",
      "Epoch 209/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4093 - accuracy: 0.8537 - mae: 0.2395 - mse: 0.1226 - val_loss: 0.4739 - val_accuracy: 0.8191 - val_mae: 0.2573 - val_mse: 0.1477\n",
      "Epoch 210/300\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.4152 - accuracy: 0.8457 - mae: 0.2402 - mse: 0.1244 - val_loss: 0.4729 - val_accuracy: 0.8191 - val_mae: 0.2459 - val_mse: 0.1477\n",
      "Epoch 211/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4030 - accuracy: 0.8537 - mae: 0.2366 - mse: 0.1208 - val_loss: 0.4775 - val_accuracy: 0.8191 - val_mae: 0.2313 - val_mse: 0.1486\n",
      "Epoch 212/300\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.4076 - accuracy: 0.8511 - mae: 0.2376 - mse: 0.1216 - val_loss: 0.4855 - val_accuracy: 0.8191 - val_mae: 0.2242 - val_mse: 0.1505\n",
      "Epoch 213/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4060 - accuracy: 0.8537 - mae: 0.2395 - mse: 0.1219 - val_loss: 0.5033 - val_accuracy: 0.8191 - val_mae: 0.2132 - val_mse: 0.1535\n",
      "Epoch 214/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4139 - accuracy: 0.8457 - mae: 0.2361 - mse: 0.1250 - val_loss: 0.4921 - val_accuracy: 0.8191 - val_mae: 0.2197 - val_mse: 0.1516\n",
      "Epoch 215/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4185 - accuracy: 0.8537 - mae: 0.2361 - mse: 0.1245 - val_loss: 0.4733 - val_accuracy: 0.8191 - val_mae: 0.2441 - val_mse: 0.1478\n",
      "Epoch 216/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.3978 - accuracy: 0.8537 - mae: 0.2319 - mse: 0.1194 - val_loss: 0.4771 - val_accuracy: 0.8085 - val_mae: 0.2803 - val_mse: 0.1483\n",
      "Epoch 217/300\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.4222 - accuracy: 0.8324 - mae: 0.2472 - mse: 0.1287 - val_loss: 0.4793 - val_accuracy: 0.8191 - val_mae: 0.2287 - val_mse: 0.1489\n",
      "Epoch 218/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4030 - accuracy: 0.8537 - mae: 0.2325 - mse: 0.1207 - val_loss: 0.4692 - val_accuracy: 0.8191 - val_mae: 0.2523 - val_mse: 0.1465\n",
      "Epoch 219/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4139 - accuracy: 0.8511 - mae: 0.2405 - mse: 0.1241 - val_loss: 0.4713 - val_accuracy: 0.8191 - val_mae: 0.2518 - val_mse: 0.1471\n",
      "Epoch 220/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4109 - accuracy: 0.8564 - mae: 0.2262 - mse: 0.1220 - val_loss: 0.5866 - val_accuracy: 0.7766 - val_mae: 0.3835 - val_mse: 0.1913\n",
      "Epoch 221/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4275 - accuracy: 0.8457 - mae: 0.2563 - mse: 0.1285 - val_loss: 0.4723 - val_accuracy: 0.8191 - val_mae: 0.2492 - val_mse: 0.1476\n",
      "Epoch 222/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4134 - accuracy: 0.8537 - mae: 0.2378 - mse: 0.1241 - val_loss: 0.4703 - val_accuracy: 0.8191 - val_mae: 0.2506 - val_mse: 0.1468\n",
      "Epoch 223/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.3951 - accuracy: 0.8537 - mae: 0.2373 - mse: 0.1189 - val_loss: 0.4793 - val_accuracy: 0.8191 - val_mae: 0.2313 - val_mse: 0.1493\n",
      "Epoch 224/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 0.3960 - accuracy: 0.8537 - mae: 0.2340 - mse: 0.1192 - val_loss: 0.4732 - val_accuracy: 0.8191 - val_mae: 0.2447 - val_mse: 0.1480\n",
      "Epoch 225/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4181 - accuracy: 0.8404 - mae: 0.2514 - mse: 0.1289 - val_loss: 0.5124 - val_accuracy: 0.8191 - val_mae: 0.2104 - val_mse: 0.1552\n",
      "Epoch 226/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4128 - accuracy: 0.8537 - mae: 0.2274 - mse: 0.1234 - val_loss: 0.4698 - val_accuracy: 0.8191 - val_mae: 0.2495 - val_mse: 0.1470\n",
      "Epoch 227/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.3936 - accuracy: 0.8537 - mae: 0.2346 - mse: 0.1185 - val_loss: 0.4717 - val_accuracy: 0.8191 - val_mae: 0.2568 - val_mse: 0.1476\n",
      "Epoch 228/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.3894 - accuracy: 0.8537 - mae: 0.2303 - mse: 0.1168 - val_loss: 0.5187 - val_accuracy: 0.7979 - val_mae: 0.3260 - val_mse: 0.1637\n",
      "Epoch 229/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.4172 - accuracy: 0.8564 - mae: 0.2424 - mse: 0.1243 - val_loss: 0.4787 - val_accuracy: 0.8191 - val_mae: 0.2366 - val_mse: 0.1495\n",
      "Epoch 230/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4050 - accuracy: 0.8590 - mae: 0.2339 - mse: 0.1220 - val_loss: 0.4703 - val_accuracy: 0.8191 - val_mae: 0.2619 - val_mse: 0.1468\n",
      "Epoch 231/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4123 - accuracy: 0.8564 - mae: 0.2413 - mse: 0.1234 - val_loss: 0.4723 - val_accuracy: 0.8191 - val_mae: 0.2593 - val_mse: 0.1475\n",
      "Epoch 232/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4033 - accuracy: 0.8564 - mae: 0.2389 - mse: 0.1215 - val_loss: 0.4811 - val_accuracy: 0.8191 - val_mae: 0.2310 - val_mse: 0.1499\n",
      "Epoch 233/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.4015 - accuracy: 0.8511 - mae: 0.2333 - mse: 0.1196 - val_loss: 0.4741 - val_accuracy: 0.8191 - val_mae: 0.2542 - val_mse: 0.1482\n",
      "Epoch 234/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4003 - accuracy: 0.8564 - mae: 0.2322 - mse: 0.1193 - val_loss: 0.4993 - val_accuracy: 0.7979 - val_mae: 0.3062 - val_mse: 0.1561\n",
      "Epoch 235/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4348 - accuracy: 0.8457 - mae: 0.2504 - mse: 0.1305 - val_loss: 0.4930 - val_accuracy: 0.8191 - val_mae: 0.2201 - val_mse: 0.1520\n",
      "Epoch 236/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.3992 - accuracy: 0.8564 - mae: 0.2250 - mse: 0.1193 - val_loss: 0.4906 - val_accuracy: 0.7979 - val_mae: 0.2938 - val_mse: 0.1529\n",
      "Epoch 237/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4037 - accuracy: 0.8511 - mae: 0.2405 - mse: 0.1206 - val_loss: 0.4777 - val_accuracy: 0.8191 - val_mae: 0.2457 - val_mse: 0.1490\n",
      "Epoch 238/300\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.4024 - accuracy: 0.8564 - mae: 0.2401 - mse: 0.1203 - val_loss: 0.5191 - val_accuracy: 0.8191 - val_mae: 0.2085 - val_mse: 0.1558\n",
      "Epoch 239/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4037 - accuracy: 0.8564 - mae: 0.2230 - mse: 0.1203 - val_loss: 0.4729 - val_accuracy: 0.8085 - val_mae: 0.2730 - val_mse: 0.1470\n",
      "Epoch 240/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.3928 - accuracy: 0.8564 - mae: 0.2341 - mse: 0.1178 - val_loss: 0.4884 - val_accuracy: 0.7979 - val_mae: 0.2919 - val_mse: 0.1523\n",
      "Epoch 241/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.3987 - accuracy: 0.8537 - mae: 0.2336 - mse: 0.1176 - val_loss: 0.4820 - val_accuracy: 0.8085 - val_mae: 0.2759 - val_mse: 0.1502\n",
      "Epoch 242/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4112 - accuracy: 0.8537 - mae: 0.2454 - mse: 0.1226 - val_loss: 0.4943 - val_accuracy: 0.8191 - val_mae: 0.2228 - val_mse: 0.1526\n",
      "Epoch 243/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.3996 - accuracy: 0.8564 - mae: 0.2288 - mse: 0.1186 - val_loss: 0.4761 - val_accuracy: 0.8191 - val_mae: 0.2433 - val_mse: 0.1486\n",
      "Epoch 244/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.3916 - accuracy: 0.8564 - mae: 0.2370 - mse: 0.1173 - val_loss: 0.5189 - val_accuracy: 0.8191 - val_mae: 0.2089 - val_mse: 0.1559\n",
      "Epoch 245/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4076 - accuracy: 0.8537 - mae: 0.2311 - mse: 0.1225 - val_loss: 0.4820 - val_accuracy: 0.8191 - val_mae: 0.2280 - val_mse: 0.1497\n",
      "Epoch 246/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.3933 - accuracy: 0.8564 - mae: 0.2358 - mse: 0.1190 - val_loss: 0.5243 - val_accuracy: 0.8191 - val_mae: 0.2058 - val_mse: 0.1561\n",
      "Epoch 247/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.3980 - accuracy: 0.8564 - mae: 0.2185 - mse: 0.1165 - val_loss: 0.5218 - val_accuracy: 0.7872 - val_mae: 0.3336 - val_mse: 0.1643\n",
      "Epoch 248/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4033 - accuracy: 0.8537 - mae: 0.2457 - mse: 0.1202 - val_loss: 0.5247 - val_accuracy: 0.8191 - val_mae: 0.2058 - val_mse: 0.1564\n",
      "Epoch 249/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4351 - accuracy: 0.8537 - mae: 0.2336 - mse: 0.1277 - val_loss: 0.4777 - val_accuracy: 0.8191 - val_mae: 0.2326 - val_mse: 0.1487\n",
      "Epoch 250/300\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.3723 - accuracy: 0.8750 - mae: 0.1978 - mse: 0.1057\n",
      "Epoch 00250: saving model to training_tf/cp-0250.ckpt\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 0.4022 - accuracy: 0.8537 - mae: 0.2366 - mse: 0.1196 - val_loss: 0.4993 - val_accuracy: 0.8191 - val_mae: 0.2154 - val_mse: 0.1527\n",
      "Epoch 251/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 0.4169 - accuracy: 0.8511 - mae: 0.2296 - mse: 0.1233 - val_loss: 0.4706 - val_accuracy: 0.8191 - val_mae: 0.2538 - val_mse: 0.1470\n",
      "Epoch 252/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.3921 - accuracy: 0.8564 - mae: 0.2347 - mse: 0.1173 - val_loss: 0.4727 - val_accuracy: 0.8191 - val_mae: 0.2444 - val_mse: 0.1475\n",
      "Epoch 253/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.4136 - accuracy: 0.8537 - mae: 0.2440 - mse: 0.1241 - val_loss: 0.4849 - val_accuracy: 0.8191 - val_mae: 0.2295 - val_mse: 0.1507\n",
      "Epoch 254/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 0.3977 - accuracy: 0.8537 - mae: 0.2312 - mse: 0.1189 - val_loss: 0.4795 - val_accuracy: 0.8191 - val_mae: 0.2362 - val_mse: 0.1494\n",
      "Epoch 255/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.3940 - accuracy: 0.8564 - mae: 0.2279 - mse: 0.1167 - val_loss: 0.4772 - val_accuracy: 0.8085 - val_mae: 0.2656 - val_mse: 0.1488\n",
      "Epoch 256/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.4087 - accuracy: 0.8590 - mae: 0.2393 - mse: 0.1201 - val_loss: 0.4868 - val_accuracy: 0.8191 - val_mae: 0.2249 - val_mse: 0.1506\n",
      "Epoch 257/300\n",
      "376/376 [==============================] - 0s 98us/sample - loss: 0.3944 - accuracy: 0.8537 - mae: 0.2316 - mse: 0.1191 - val_loss: 0.4768 - val_accuracy: 0.8191 - val_mae: 0.2362 - val_mse: 0.1483\n",
      "Epoch 258/300\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.4120 - accuracy: 0.8457 - mae: 0.2409 - mse: 0.1235 - val_loss: 0.4937 - val_accuracy: 0.8191 - val_mae: 0.2207 - val_mse: 0.1521\n",
      "Epoch 259/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4165 - accuracy: 0.8511 - mae: 0.2424 - mse: 0.1257 - val_loss: 0.5232 - val_accuracy: 0.8191 - val_mae: 0.2069 - val_mse: 0.1565\n",
      "Epoch 260/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4101 - accuracy: 0.8564 - mae: 0.2168 - mse: 0.1205 - val_loss: 0.5006 - val_accuracy: 0.7979 - val_mae: 0.3135 - val_mse: 0.1565\n",
      "Epoch 261/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.3911 - accuracy: 0.8564 - mae: 0.2401 - mse: 0.1179 - val_loss: 0.4723 - val_accuracy: 0.8191 - val_mae: 0.2514 - val_mse: 0.1477\n",
      "Epoch 262/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4082 - accuracy: 0.8564 - mae: 0.2296 - mse: 0.1218 - val_loss: 0.5174 - val_accuracy: 0.7766 - val_mae: 0.3304 - val_mse: 0.1629\n",
      "Epoch 263/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.3968 - accuracy: 0.8564 - mae: 0.2437 - mse: 0.1189 - val_loss: 0.4789 - val_accuracy: 0.8191 - val_mae: 0.2298 - val_mse: 0.1492\n",
      "Epoch 264/300\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.3905 - accuracy: 0.8537 - mae: 0.2381 - mse: 0.1187 - val_loss: 0.5297 - val_accuracy: 0.8191 - val_mae: 0.2044 - val_mse: 0.1570\n",
      "Epoch 265/300\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.4018 - accuracy: 0.8537 - mae: 0.2250 - mse: 0.1183 - val_loss: 0.4744 - val_accuracy: 0.8191 - val_mae: 0.2369 - val_mse: 0.1483\n",
      "Epoch 266/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.3889 - accuracy: 0.8564 - mae: 0.2302 - mse: 0.1168 - val_loss: 0.4778 - val_accuracy: 0.8085 - val_mae: 0.2785 - val_mse: 0.1492\n",
      "Epoch 267/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.3964 - accuracy: 0.8537 - mae: 0.2361 - mse: 0.1199 - val_loss: 0.4755 - val_accuracy: 0.8085 - val_mae: 0.2671 - val_mse: 0.1487\n",
      "Epoch 268/300\n",
      "376/376 [==============================] - 0s 96us/sample - loss: 0.4040 - accuracy: 0.8537 - mae: 0.2353 - mse: 0.1220 - val_loss: 0.4732 - val_accuracy: 0.8191 - val_mae: 0.2620 - val_mse: 0.1480\n",
      "Epoch 269/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.3903 - accuracy: 0.8564 - mae: 0.2310 - mse: 0.1165 - val_loss: 0.5085 - val_accuracy: 0.7979 - val_mae: 0.3101 - val_mse: 0.1599\n",
      "Epoch 270/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.3911 - accuracy: 0.8537 - mae: 0.2367 - mse: 0.1173 - val_loss: 0.4788 - val_accuracy: 0.8191 - val_mae: 0.2390 - val_mse: 0.1496\n",
      "Epoch 271/300\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.4302 - accuracy: 0.8511 - mae: 0.2423 - mse: 0.1285 - val_loss: 0.4736 - val_accuracy: 0.8191 - val_mae: 0.2501 - val_mse: 0.1483\n",
      "Epoch 272/300\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.4194 - accuracy: 0.8457 - mae: 0.2502 - mse: 0.1268 - val_loss: 0.5041 - val_accuracy: 0.8191 - val_mae: 0.2137 - val_mse: 0.1539\n",
      "Epoch 273/300\n",
      "376/376 [==============================] - 0s 74us/sample - loss: 0.4011 - accuracy: 0.8564 - mae: 0.2231 - mse: 0.1184 - val_loss: 0.4751 - val_accuracy: 0.8085 - val_mae: 0.2668 - val_mse: 0.1486\n",
      "Epoch 274/300\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.3904 - accuracy: 0.8564 - mae: 0.2319 - mse: 0.1171 - val_loss: 0.4854 - val_accuracy: 0.8085 - val_mae: 0.2911 - val_mse: 0.1518\n",
      "Epoch 275/300\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.4127 - accuracy: 0.8511 - mae: 0.2395 - mse: 0.1220 - val_loss: 0.4818 - val_accuracy: 0.8085 - val_mae: 0.2735 - val_mse: 0.1508\n",
      "Epoch 276/300\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.3898 - accuracy: 0.8564 - mae: 0.2333 - mse: 0.1167 - val_loss: 0.4765 - val_accuracy: 0.8191 - val_mae: 0.2586 - val_mse: 0.1491\n",
      "Epoch 277/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4011 - accuracy: 0.8564 - mae: 0.2289 - mse: 0.1200 - val_loss: 0.5336 - val_accuracy: 0.7766 - val_mae: 0.3418 - val_mse: 0.1696\n",
      "Epoch 278/300\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.4038 - accuracy: 0.8564 - mae: 0.2448 - mse: 0.1214 - val_loss: 0.4789 - val_accuracy: 0.8191 - val_mae: 0.2606 - val_mse: 0.1496\n",
      "Epoch 279/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.3873 - accuracy: 0.8564 - mae: 0.2330 - mse: 0.1165 - val_loss: 0.4798 - val_accuracy: 0.8191 - val_mae: 0.2325 - val_mse: 0.1494\n",
      "Epoch 280/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4146 - accuracy: 0.8511 - mae: 0.2405 - mse: 0.1258 - val_loss: 0.4782 - val_accuracy: 0.8191 - val_mae: 0.2384 - val_mse: 0.1490\n",
      "Epoch 281/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.3874 - accuracy: 0.8564 - mae: 0.2279 - mse: 0.1161 - val_loss: 0.4848 - val_accuracy: 0.8085 - val_mae: 0.2852 - val_mse: 0.1511\n",
      "Epoch 282/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.3925 - accuracy: 0.8564 - mae: 0.2289 - mse: 0.1176 - val_loss: 0.6013 - val_accuracy: 0.7340 - val_mae: 0.3862 - val_mse: 0.1985\n",
      "Epoch 283/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.3845 - accuracy: 0.8564 - mae: 0.2436 - mse: 0.1167 - val_loss: 0.5215 - val_accuracy: 0.8191 - val_mae: 0.2069 - val_mse: 0.1558\n",
      "Epoch 284/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 0.4120 - accuracy: 0.8590 - mae: 0.2353 - mse: 0.1217 - val_loss: 0.5212 - val_accuracy: 0.8191 - val_mae: 0.2073 - val_mse: 0.1560\n",
      "Epoch 285/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4144 - accuracy: 0.8564 - mae: 0.2320 - mse: 0.1241 - val_loss: 0.4930 - val_accuracy: 0.8191 - val_mae: 0.2208 - val_mse: 0.1521\n",
      "Epoch 286/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 0.3861 - accuracy: 0.8564 - mae: 0.2228 - mse: 0.1153 - val_loss: 0.4874 - val_accuracy: 0.8085 - val_mae: 0.2878 - val_mse: 0.1521\n",
      "Epoch 287/300\n",
      "376/376 [==============================] - 0s 104us/sample - loss: 0.3997 - accuracy: 0.8564 - mae: 0.2382 - mse: 0.1204 - val_loss: 0.4723 - val_accuracy: 0.8191 - val_mae: 0.2584 - val_mse: 0.1473\n",
      "Epoch 288/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.4051 - accuracy: 0.8564 - mae: 0.2426 - mse: 0.1200 - val_loss: 0.5135 - val_accuracy: 0.8191 - val_mae: 0.2107 - val_mse: 0.1551\n",
      "Epoch 289/300\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.4003 - accuracy: 0.8511 - mae: 0.2312 - mse: 0.1197 - val_loss: 0.4951 - val_accuracy: 0.8191 - val_mae: 0.2202 - val_mse: 0.1523\n",
      "Epoch 290/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.4064 - accuracy: 0.8590 - mae: 0.2324 - mse: 0.1206 - val_loss: 0.4778 - val_accuracy: 0.8191 - val_mae: 0.2405 - val_mse: 0.1490\n",
      "Epoch 291/300\n",
      "376/376 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.8281 - mae: 0.2379 - mse: 0.12 - 0s 88us/sample - loss: 0.3834 - accuracy: 0.8564 - mae: 0.2281 - mse: 0.1152 - val_loss: 0.4992 - val_accuracy: 0.7979 - val_mae: 0.2977 - val_mse: 0.1562\n",
      "Epoch 292/300\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.3846 - accuracy: 0.8564 - mae: 0.2392 - mse: 0.1166 - val_loss: 0.5292 - val_accuracy: 0.8191 - val_mae: 0.2066 - val_mse: 0.1575\n",
      "Epoch 293/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.4354 - accuracy: 0.8351 - mae: 0.2443 - mse: 0.1330 - val_loss: 0.4958 - val_accuracy: 0.8191 - val_mae: 0.2214 - val_mse: 0.1527\n",
      "Epoch 294/300\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.3802 - accuracy: 0.8564 - mae: 0.2190 - mse: 0.1143 - val_loss: 0.4936 - val_accuracy: 0.7979 - val_mae: 0.2939 - val_mse: 0.1543\n",
      "Epoch 295/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.3927 - accuracy: 0.8564 - mae: 0.2392 - mse: 0.1175 - val_loss: 0.4918 - val_accuracy: 0.8191 - val_mae: 0.2237 - val_mse: 0.1518\n",
      "Epoch 296/300\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.3963 - accuracy: 0.8537 - mae: 0.2294 - mse: 0.1185 - val_loss: 0.4783 - val_accuracy: 0.8191 - val_mae: 0.2395 - val_mse: 0.1491\n",
      "Epoch 297/300\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.3869 - accuracy: 0.8537 - mae: 0.2268 - mse: 0.1161 - val_loss: 0.5462 - val_accuracy: 0.7766 - val_mae: 0.3454 - val_mse: 0.1747\n",
      "Epoch 298/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.4164 - accuracy: 0.8537 - mae: 0.2433 - mse: 0.1244 - val_loss: 0.4808 - val_accuracy: 0.8191 - val_mae: 0.2410 - val_mse: 0.1495\n",
      "Epoch 299/300\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.3941 - accuracy: 0.8537 - mae: 0.2298 - mse: 0.1185 - val_loss: 0.4789 - val_accuracy: 0.8085 - val_mae: 0.2697 - val_mse: 0.1489\n",
      "Epoch 300/300\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.4345 - accuracy: 0.8125 - mae: 0.2741 - mse: 0.1370\n",
      "Epoch 00300: saving model to training_tf/cp-0300.ckpt\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 0.3856 - accuracy: 0.8564 - mae: 0.2331 - mse: 0.1157 - val_loss: 0.5042 - val_accuracy: 0.7979 - val_mae: 0.3024 - val_mse: 0.1577\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, \n",
    "                    validation_split = 0.2,\n",
    "                    #validation_data=(X, Y),\n",
    "                    epochs=300, \n",
    "                    batch_size=64,\n",
    "                    verbose=1,  # Verbosity mode. 0 = silent, 1 = progress bar(default), 2 = one line per epoch. \n",
    "                    callbacks=cp_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints_tf/my_checkpoint') # 수동으로 가중치 저장하기\n",
    "path = \"./saved_model_tf\"\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "model.save('./saved_model_tf') # 전체 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                540       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "470/470 - 0s - loss: 0.3968 - accuracy: 0.8532 - mae: 0.2468 - mse: 0.1172\n",
      "복원된 모델의 정확도: 85.32%\n",
      "(470, 1)\n"
     ]
    }
   ],
   "source": [
    "'''모델 전체 불러오기'''\n",
    "new_model = tf.keras.models.load_model('./saved_model_tf') # 전체 모델 불러오기\n",
    "\n",
    "# 모델 구조를 확인합니다\n",
    "new_model.summary()\n",
    "\n",
    "# 복원된 모델을 평가합니다\n",
    "loss, acc, mae, mse= new_model.evaluate(X,  Y, verbose=2)\n",
    "print('복원된 모델의 정확도: {:5.2f}%'.format(100*acc))\n",
    "\n",
    "print(new_model.predict(X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 - 0s - loss: 0.4777 - accuracy: 0.8021 - mae: 0.2936 - mse: 0.1517\n",
      "0.4776763604042378\n",
      "복원된 모델의 정확도: 80.21%\n",
      "(470, 1)\n"
     ]
    }
   ],
   "source": [
    "'''모델 weight 불러오기'''\n",
    "checkpoint_path = \"training_tf/cp-0003.ckpt\"\n",
    "# checkpoint_path = './checkpoints/my_checkpoint'\n",
    "model.load_weights(checkpoint_path) # \n",
    "\n",
    "loss, acc, mae, mse = model.evaluate(X, Y, verbose=2)\n",
    "print(loss)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "print(model.predict(X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
