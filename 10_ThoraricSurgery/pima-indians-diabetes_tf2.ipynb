{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피마 인디언의 당뇨병 예측 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "    0   1     2     3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
      "0  293   1  3.80  2.80   0   0   0   0   0   0  12   0   0   0   1   0  62   0\n",
      "1    1   2  2.88  2.16   1   0   0   0   1   1  14   0   0   0   1   0  60   0\n",
      "2    8   2  3.19  2.50   1   0   0   0   1   0  11   0   0   1   1   0  66   1\n",
      "3   14   2  3.98  3.06   2   0   0   0   1   1  14   0   0   0   1   0  80   1\n",
      "4   17   2  2.21  1.88   0   0   1   0   0   0  12   0   0   0   1   0  56   0\n",
      "     0  1     2     3  4  5  6  7  8  9  10  11  12  13  14  15  16  class\n",
      "0  293  1  3.80  2.80  0  0  0  0  0  0  12   0   0   0   1   0  62      0\n",
      "1    1  2  2.88  2.16  1  0  0  0  1  1  14   0   0   0   1   0  60      0\n",
      "2    8  2  3.19  2.50  1  0  0  0  1  0  11   0   0   1   1   0  66      1\n",
      "3   14  2  3.98  3.06  2  0  0  0  1  1  14   0   0   0   1   0  80      1\n",
      "4   17  2  2.21  1.88  0  0  1  0  0  0  12   0   0   0   1   0  56      0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 딥러닝을 구동하는 데 필요한 케라스 함수 호출\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "print(tf.__version__)\n",
    "\n",
    "# 필요한 라이브러리 불러옴\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "'''\n",
    "# 준비된 수술 환자 데이터를 불러옴\n",
    "Data_set = np.loadtxt(\"../dataset/ThoraricSurgery.csv\", delimiter=',')\n",
    "\n",
    "# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
    "X = Data_set[:, 0:17]\n",
    "Y = Data_set[:, 17]\n",
    "'''\n",
    "\n",
    "# 준비된 수술 환자 데이터를 불러옴 by using pandas\n",
    "#df = pd.read_csv(\"../dataset/ThoraricSurgery.csv\",\n",
    "#                      names=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"class\"])\n",
    "df = pd.read_csv(\"../dataset/ThoraricSurgery.csv\", header=None)\n",
    "print(df.head())\n",
    "df.rename(columns={17:\"class\"}, inplace=True)\n",
    "print(df.head())\n",
    "\n",
    "# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
    "X = df.drop(['class'], axis=1, inplace=False).values\n",
    "Y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 딥러닝 구조를 결정(모델을 설정하고 실행하는 부분)\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=17, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 딥러닝 실행\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "'''\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        #tf.keras.layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "        tf.keras.layers.Dense(30, input_dim=17, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),        \n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy', 'mae', 'mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "'''\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 모델의 가중치를 저장하는 콜백 만들기\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "'''\n",
    "\n",
    "# 파일 이름에 에포크 번호를 포함시킵니다(`str.format` 포맷)\n",
    "checkpoint_path = \"training_tf/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "\n",
    "# 열 번째 에포크마다 가중치를 저장하기 위한 콜백을 만듭니다\n",
    "\n",
    "\n",
    "\n",
    "cp_callback = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50, baseline=0.4),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        monitor='val_loss',\n",
    "        #mode='min',        \n",
    "        verbose=1, # verbosity mode, 0 or 1.\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,    \n",
    "        save_freq='epoch')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 30)                540       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 376 samples, validate on 94 samples\n",
      "Epoch 1/200\n",
      " 64/376 [====>.........................] - ETA: 1s - loss: 0.1796 - accuracy: 0.7344 - mae: 0.2404 - mse: 0.1796\n",
      "Epoch 00001: val_loss improved from inf to 0.16018, saving model to training_tf/cp-0001.ckpt\n",
      "376/376 [==============================] - 1s 2ms/sample - loss: 0.1496 - accuracy: 0.8298 - mae: 0.1838 - mse: 0.1496 - val_loss: 0.1602 - val_accuracy: 0.8298 - val_mae: 0.1743 - val_mse: 0.1602\n",
      "Epoch 2/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1134 - accuracy: 0.8906 - mae: 0.1375 - mse: 0.1134\n",
      "Epoch 00002: val_loss did not improve from 0.16018\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.1406 - accuracy: 0.8564 - mae: 0.1637 - mse: 0.1406 - val_loss: 0.1609 - val_accuracy: 0.8298 - val_mae: 0.1738 - val_mse: 0.1609\n",
      "Epoch 3/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1201 - accuracy: 0.8750 - mae: 0.1465 - mse: 0.1201\n",
      "Epoch 00003: val_loss improved from 0.16018 to 0.15952, saving model to training_tf/cp-0003.ckpt\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 0.1401 - accuracy: 0.8564 - mae: 0.1615 - mse: 0.1401 - val_loss: 0.1595 - val_accuracy: 0.8298 - val_mae: 0.1745 - val_mse: 0.1595\n",
      "Epoch 4/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1469 - accuracy: 0.8438 - mae: 0.1726 - mse: 0.1469\n",
      "Epoch 00004: val_loss did not improve from 0.15952\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1413 - accuracy: 0.8564 - mae: 0.1874 - mse: 0.1413 - val_loss: 0.1607 - val_accuracy: 0.8298 - val_mae: 0.1744 - val_mse: 0.1607\n",
      "Epoch 5/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1674 - accuracy: 0.8281 - mae: 0.1925 - mse: 0.1674\n",
      "Epoch 00005: val_loss improved from 0.15952 to 0.15222, saving model to training_tf/cp-0005.ckpt\n",
      "376/376 [==============================] - 0s 994us/sample - loss: 0.1363 - accuracy: 0.8564 - mae: 0.1728 - mse: 0.1363 - val_loss: 0.1522 - val_accuracy: 0.8298 - val_mae: 0.1905 - val_mse: 0.1522\n",
      "Epoch 6/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1079 - accuracy: 0.8906 - mae: 0.1647 - mse: 0.1079\n",
      "Epoch 00006: val_loss did not improve from 0.15222\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.1413 - accuracy: 0.8431 - mae: 0.2119 - mse: 0.1413 - val_loss: 0.1580 - val_accuracy: 0.8298 - val_mae: 0.1774 - val_mse: 0.1580\n",
      "Epoch 7/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1028 - accuracy: 0.8906 - mae: 0.1341 - mse: 0.1028\n",
      "Epoch 00007: val_loss did not improve from 0.15222\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1344 - accuracy: 0.8564 - mae: 0.1762 - mse: 0.1344 - val_loss: 0.1527 - val_accuracy: 0.8298 - val_mae: 0.1881 - val_mse: 0.1527\n",
      "Epoch 8/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1199 - accuracy: 0.8750 - mae: 0.1797 - mse: 0.1199\n",
      "Epoch 00008: val_loss did not improve from 0.15222\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.1300 - accuracy: 0.8564 - mae: 0.2157 - mse: 0.1300 - val_loss: 0.1548 - val_accuracy: 0.8298 - val_mae: 0.1824 - val_mse: 0.1548\n",
      "Epoch 9/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1513 - accuracy: 0.8438 - mae: 0.1984 - mse: 0.1513\n",
      "Epoch 00009: val_loss improved from 0.15222 to 0.14781, saving model to training_tf/cp-0009.ckpt\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 0.1292 - accuracy: 0.8564 - mae: 0.1969 - mse: 0.1292 - val_loss: 0.1478 - val_accuracy: 0.8298 - val_mae: 0.2054 - val_mse: 0.1478\n",
      "Epoch 10/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0653 - accuracy: 0.9375 - mae: 0.1476 - mse: 0.0653\n",
      "Epoch 00010: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.1287 - accuracy: 0.8564 - mae: 0.2137 - mse: 0.1287 - val_loss: 0.1524 - val_accuracy: 0.8298 - val_mae: 0.1896 - val_mse: 0.1524\n",
      "Epoch 11/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1204 - accuracy: 0.8594 - mae: 0.1818 - mse: 0.1204\n",
      "Epoch 00011: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.1252 - accuracy: 0.8564 - mae: 0.2224 - mse: 0.1252 - val_loss: 0.1528 - val_accuracy: 0.8298 - val_mae: 0.1915 - val_mse: 0.1528\n",
      "Epoch 12/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1153 - accuracy: 0.8750 - mae: 0.1739 - mse: 0.1153\n",
      "Epoch 00012: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.1286 - accuracy: 0.8564 - mae: 0.2054 - mse: 0.1286 - val_loss: 0.1506 - val_accuracy: 0.8298 - val_mae: 0.2000 - val_mse: 0.1506\n",
      "Epoch 13/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1155 - accuracy: 0.8594 - mae: 0.1865 - mse: 0.1155\n",
      "Epoch 00013: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.1302 - accuracy: 0.8564 - mae: 0.2323 - mse: 0.1302 - val_loss: 0.1604 - val_accuracy: 0.8298 - val_mae: 0.1753 - val_mse: 0.1604\n",
      "Epoch 14/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0920 - accuracy: 0.9062 - mae: 0.1166 - mse: 0.0920\n",
      "Epoch 00014: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1331 - accuracy: 0.8564 - mae: 0.1691 - mse: 0.1331 - val_loss: 0.1510 - val_accuracy: 0.8298 - val_mae: 0.1916 - val_mse: 0.1510\n",
      "Epoch 15/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1304 - accuracy: 0.8594 - mae: 0.2014 - mse: 0.1304\n",
      "Epoch 00015: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.1275 - accuracy: 0.8590 - mae: 0.2143 - mse: 0.1275 - val_loss: 0.1499 - val_accuracy: 0.8298 - val_mae: 0.2019 - val_mse: 0.1499\n",
      "Epoch 16/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0863 - accuracy: 0.9062 - mae: 0.1696 - mse: 0.0863\n",
      "Epoch 00016: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.1261 - accuracy: 0.8537 - mae: 0.2198 - mse: 0.1261 - val_loss: 0.1507 - val_accuracy: 0.8298 - val_mae: 0.1945 - val_mse: 0.1507\n",
      "Epoch 17/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0580 - accuracy: 0.9375 - mae: 0.1273 - mse: 0.0580\n",
      "Epoch 00017: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1263 - accuracy: 0.8564 - mae: 0.2190 - mse: 0.1263 - val_loss: 0.1485 - val_accuracy: 0.8298 - val_mae: 0.2075 - val_mse: 0.1485\n",
      "Epoch 18/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1231 - accuracy: 0.8594 - mae: 0.2204 - mse: 0.1231\n",
      "Epoch 00018: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.1241 - accuracy: 0.8564 - mae: 0.2194 - mse: 0.1241 - val_loss: 0.1496 - val_accuracy: 0.8298 - val_mae: 0.2020 - val_mse: 0.1496\n",
      "Epoch 19/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1538 - accuracy: 0.8125 - mae: 0.2435 - mse: 0.1538\n",
      "Epoch 00019: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1346 - accuracy: 0.8511 - mae: 0.2068 - mse: 0.1346 - val_loss: 0.1552 - val_accuracy: 0.8298 - val_mae: 0.1849 - val_mse: 0.1552\n",
      "Epoch 20/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1815 - accuracy: 0.7969 - mae: 0.2424 - mse: 0.1815\n",
      "Epoch 00020: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.1280 - accuracy: 0.8564 - mae: 0.2110 - mse: 0.1280 - val_loss: 0.1507 - val_accuracy: 0.8298 - val_mae: 0.1976 - val_mse: 0.1507\n",
      "Epoch 21/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1235 - accuracy: 0.8594 - mae: 0.2063 - mse: 0.1235\n",
      "Epoch 00021: val_loss did not improve from 0.14781\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1259 - accuracy: 0.8590 - mae: 0.2170 - mse: 0.1259 - val_loss: 0.1560 - val_accuracy: 0.8298 - val_mae: 0.1824 - val_mse: 0.1560\n",
      "Epoch 22/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1313 - accuracy: 0.8594 - mae: 0.1730 - mse: 0.1313\n",
      "Epoch 00022: val_loss improved from 0.14781 to 0.14614, saving model to training_tf/cp-0022.ckpt\n",
      "376/376 [==============================] - 0s 957us/sample - loss: 0.1247 - accuracy: 0.8564 - mae: 0.2073 - mse: 0.1247 - val_loss: 0.1461 - val_accuracy: 0.8298 - val_mae: 0.2240 - val_mse: 0.1461\n",
      "Epoch 23/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1475 - accuracy: 0.8281 - mae: 0.2607 - mse: 0.1475\n",
      "Epoch 00023: val_loss did not improve from 0.14614\n",
      "376/376 [==============================] - 0s 101us/sample - loss: 0.1324 - accuracy: 0.8537 - mae: 0.2211 - mse: 0.1324 - val_loss: 0.1556 - val_accuracy: 0.8298 - val_mae: 0.1856 - val_mse: 0.1556\n",
      "Epoch 24/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0767 - accuracy: 0.9219 - mae: 0.1308 - mse: 0.0767\n",
      "Epoch 00024: val_loss did not improve from 0.14614\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.1226 - accuracy: 0.8590 - mae: 0.2116 - mse: 0.1226 - val_loss: 0.1629 - val_accuracy: 0.8298 - val_mae: 0.3104 - val_mse: 0.1629\n",
      "Epoch 25/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1860 - accuracy: 0.7656 - mae: 0.3497 - mse: 0.1860\n",
      "Epoch 00025: val_loss did not improve from 0.14614\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1257 - accuracy: 0.8564 - mae: 0.2143 - mse: 0.1257 - val_loss: 0.1546 - val_accuracy: 0.8298 - val_mae: 0.1876 - val_mse: 0.1546\n",
      "Epoch 26/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1014 - accuracy: 0.8906 - mae: 0.1589 - mse: 0.1014\n",
      "Epoch 00026: val_loss did not improve from 0.14614\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1330 - accuracy: 0.8511 - mae: 0.2122 - mse: 0.1330 - val_loss: 0.1575 - val_accuracy: 0.8298 - val_mae: 0.1793 - val_mse: 0.1575\n",
      "Epoch 27/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0936 - accuracy: 0.8906 - mae: 0.1443 - mse: 0.0936\n",
      "Epoch 00027: val_loss did not improve from 0.14614\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1281 - accuracy: 0.8537 - mae: 0.1906 - mse: 0.1281 - val_loss: 0.1487 - val_accuracy: 0.8298 - val_mae: 0.2055 - val_mse: 0.1487\n",
      "Epoch 28/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1047 - accuracy: 0.8750 - mae: 0.1943 - mse: 0.1047\n",
      "Epoch 00028: val_loss did not improve from 0.14614\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.1274 - accuracy: 0.8511 - mae: 0.2311 - mse: 0.1274 - val_loss: 0.1580 - val_accuracy: 0.8298 - val_mae: 0.1806 - val_mse: 0.1580\n",
      "Epoch 29/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1269 - accuracy: 0.8594 - mae: 0.1718 - mse: 0.1269\n",
      "Epoch 00029: val_loss did not improve from 0.14614\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.1260 - accuracy: 0.8564 - mae: 0.2008 - mse: 0.1260 - val_loss: 0.1482 - val_accuracy: 0.8298 - val_mae: 0.2063 - val_mse: 0.1482\n",
      "Epoch 30/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1197 - accuracy: 0.8750 - mae: 0.2013 - mse: 0.1197\n",
      "Epoch 00030: val_loss did not improve from 0.14614\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.1251 - accuracy: 0.8590 - mae: 0.2231 - mse: 0.1251 - val_loss: 0.1562 - val_accuracy: 0.8298 - val_mae: 0.1822 - val_mse: 0.1562\n",
      "Epoch 31/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1677 - accuracy: 0.8125 - mae: 0.2195 - mse: 0.1677\n",
      "Epoch 00031: val_loss did not improve from 0.14614\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.1243 - accuracy: 0.8564 - mae: 0.2023 - mse: 0.1243 - val_loss: 0.1542 - val_accuracy: 0.8298 - val_mae: 0.2960 - val_mse: 0.1542\n",
      "Epoch 32/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1302 - accuracy: 0.8438 - mae: 0.3053 - mse: 0.1302\n",
      "Epoch 00032: val_loss improved from 0.14614 to 0.14460, saving model to training_tf/cp-0032.ckpt\n",
      "376/376 [==============================] - 0s 944us/sample - loss: 0.1268 - accuracy: 0.8537 - mae: 0.2079 - mse: 0.1268 - val_loss: 0.1446 - val_accuracy: 0.8298 - val_mae: 0.2362 - val_mse: 0.1446\n",
      "Epoch 33/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1164 - accuracy: 0.8438 - mae: 0.2542 - mse: 0.1164\n",
      "Epoch 00033: val_loss did not improve from 0.14460\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.1240 - accuracy: 0.8590 - mae: 0.2306 - mse: 0.1240 - val_loss: 0.1545 - val_accuracy: 0.8298 - val_mae: 0.1862 - val_mse: 0.1545\n",
      "Epoch 34/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1056 - accuracy: 0.8594 - mae: 0.1739 - mse: 0.1056\n",
      "Epoch 00034: val_loss did not improve from 0.14460\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.1617 - accuracy: 0.7766 - mae: 0.2601 - mse: 0.1617 - val_loss: 0.1566 - val_accuracy: 0.8298 - val_mae: 0.1841 - val_mse: 0.1566\n",
      "Epoch 35/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1085 - accuracy: 0.8750 - mae: 0.1654 - mse: 0.1085\n",
      "Epoch 00035: val_loss did not improve from 0.14460\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.1250 - accuracy: 0.8564 - mae: 0.1950 - mse: 0.1250 - val_loss: 0.1502 - val_accuracy: 0.8298 - val_mae: 0.2023 - val_mse: 0.1502\n",
      "Epoch 36/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1198 - accuracy: 0.8594 - mae: 0.2091 - mse: 0.1198\n",
      "Epoch 00036: val_loss did not improve from 0.14460\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.1221 - accuracy: 0.8564 - mae: 0.2246 - mse: 0.1221 - val_loss: 0.1497 - val_accuracy: 0.8298 - val_mae: 0.2091 - val_mse: 0.1497\n",
      "Epoch 37/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1197 - accuracy: 0.8594 - mae: 0.2194 - mse: 0.1197\n",
      "Epoch 00037: val_loss did not improve from 0.14460\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.1221 - accuracy: 0.8564 - mae: 0.2299 - mse: 0.1221 - val_loss: 0.1514 - val_accuracy: 0.8298 - val_mae: 0.1991 - val_mse: 0.1514\n",
      "Epoch 38/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1380 - accuracy: 0.8281 - mae: 0.2268 - mse: 0.1380\n",
      "Epoch 00038: val_loss did not improve from 0.14460\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.1268 - accuracy: 0.8537 - mae: 0.2214 - mse: 0.1268 - val_loss: 0.1525 - val_accuracy: 0.8298 - val_mae: 0.1948 - val_mse: 0.1525\n",
      "Epoch 39/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1171 - accuracy: 0.8750 - mae: 0.1941 - mse: 0.1171\n",
      "Epoch 00039: val_loss did not improve from 0.14460\n",
      "376/376 [==============================] - 0s 93us/sample - loss: 0.1233 - accuracy: 0.8511 - mae: 0.2240 - mse: 0.1233 - val_loss: 0.1553 - val_accuracy: 0.8298 - val_mae: 0.1846 - val_mse: 0.1553\n",
      "Epoch 40/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1116 - accuracy: 0.8750 - mae: 0.1624 - mse: 0.1116\n",
      "Epoch 00040: val_loss did not improve from 0.14460\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.1222 - accuracy: 0.8564 - mae: 0.2133 - mse: 0.1222 - val_loss: 0.1502 - val_accuracy: 0.8298 - val_mae: 0.2744 - val_mse: 0.1502\n",
      "Epoch 41/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1549 - accuracy: 0.7656 - mae: 0.3222 - mse: 0.1549\n",
      "Epoch 00041: val_loss did not improve from 0.14460\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.1184 - accuracy: 0.8537 - mae: 0.2241 - mse: 0.1184 - val_loss: 0.1498 - val_accuracy: 0.8298 - val_mae: 0.2049 - val_mse: 0.1498\n",
      "Epoch 42/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1716 - accuracy: 0.7969 - mae: 0.2594 - mse: 0.1716\n",
      "Epoch 00042: val_loss did not improve from 0.14460\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1339 - accuracy: 0.8564 - mae: 0.2093 - mse: 0.1339 - val_loss: 0.1566 - val_accuracy: 0.8298 - val_mae: 0.1814 - val_mse: 0.1566\n",
      "Epoch 43/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1370 - accuracy: 0.8594 - mae: 0.1851 - mse: 0.1370\n",
      "Epoch 00043: val_loss improved from 0.14460 to 0.14418, saving model to training_tf/cp-0043.ckpt\n",
      "376/376 [==============================] - 0s 928us/sample - loss: 0.1243 - accuracy: 0.8564 - mae: 0.1988 - mse: 0.1243 - val_loss: 0.1442 - val_accuracy: 0.8298 - val_mae: 0.2303 - val_mse: 0.1442\n",
      "Epoch 44/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1823 - accuracy: 0.7656 - mae: 0.3240 - mse: 0.1823\n",
      "Epoch 00044: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 90us/sample - loss: 0.1259 - accuracy: 0.8564 - mae: 0.2327 - mse: 0.1259 - val_loss: 0.1592 - val_accuracy: 0.8298 - val_mae: 0.1781 - val_mse: 0.1592\n",
      "Epoch 45/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1132 - accuracy: 0.8750 - mae: 0.1555 - mse: 0.1132\n",
      "Epoch 00045: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.1240 - accuracy: 0.8564 - mae: 0.1896 - mse: 0.1240 - val_loss: 0.1764 - val_accuracy: 0.8404 - val_mae: 0.3518 - val_mse: 0.1764\n",
      "Epoch 46/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1788 - accuracy: 0.7969 - mae: 0.3698 - mse: 0.1788\n",
      "Epoch 00046: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.1326 - accuracy: 0.8511 - mae: 0.2104 - mse: 0.1326 - val_loss: 0.1518 - val_accuracy: 0.8298 - val_mae: 0.1937 - val_mse: 0.1518\n",
      "Epoch 47/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1595 - accuracy: 0.7969 - mae: 0.2423 - mse: 0.1595\n",
      "Epoch 00047: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.1223 - accuracy: 0.8537 - mae: 0.2287 - mse: 0.1223 - val_loss: 0.1525 - val_accuracy: 0.8298 - val_mae: 0.1973 - val_mse: 0.1525\n",
      "Epoch 48/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0646 - accuracy: 0.9219 - mae: 0.1462 - mse: 0.0646\n",
      "Epoch 00048: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.1250 - accuracy: 0.8537 - mae: 0.2188 - mse: 0.1250 - val_loss: 0.1570 - val_accuracy: 0.8298 - val_mae: 0.1814 - val_mse: 0.1570\n",
      "Epoch 49/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.2054 - accuracy: 0.7656 - mae: 0.2585 - mse: 0.2054\n",
      "Epoch 00049: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.1267 - accuracy: 0.8564 - mae: 0.2086 - mse: 0.1267 - val_loss: 0.1537 - val_accuracy: 0.8298 - val_mae: 0.1890 - val_mse: 0.1537\n",
      "Epoch 50/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0887 - accuracy: 0.8906 - mae: 0.1582 - mse: 0.0887\n",
      "Epoch 00050: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1201 - accuracy: 0.8590 - mae: 0.2178 - mse: 0.1201 - val_loss: 0.1483 - val_accuracy: 0.8298 - val_mae: 0.2170 - val_mse: 0.1483\n",
      "Epoch 51/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1624 - accuracy: 0.7969 - mae: 0.2628 - mse: 0.1624\n",
      "Epoch 00051: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.1311 - accuracy: 0.8564 - mae: 0.2083 - mse: 0.1311 - val_loss: 0.1518 - val_accuracy: 0.8298 - val_mae: 0.1934 - val_mse: 0.1518\n",
      "Epoch 52/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0708 - accuracy: 0.9062 - mae: 0.1517 - mse: 0.0708\n",
      "Epoch 00052: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1242 - accuracy: 0.8511 - mae: 0.2185 - mse: 0.1242 - val_loss: 0.1493 - val_accuracy: 0.8298 - val_mae: 0.2045 - val_mse: 0.1493\n",
      "Epoch 53/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1624 - accuracy: 0.7969 - mae: 0.2649 - mse: 0.1624\n",
      "Epoch 00053: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1213 - accuracy: 0.8564 - mae: 0.2227 - mse: 0.1213 - val_loss: 0.1560 - val_accuracy: 0.8298 - val_mae: 0.2932 - val_mse: 0.1560\n",
      "Epoch 54/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1005 - accuracy: 0.8906 - mae: 0.2646 - mse: 0.1005\n",
      "Epoch 00054: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1258 - accuracy: 0.8590 - mae: 0.2123 - mse: 0.1258 - val_loss: 0.1514 - val_accuracy: 0.8298 - val_mae: 0.1999 - val_mse: 0.1514\n",
      "Epoch 55/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0670 - accuracy: 0.9219 - mae: 0.1556 - mse: 0.0670\n",
      "Epoch 00055: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1301 - accuracy: 0.8564 - mae: 0.2205 - mse: 0.1301 - val_loss: 0.1572 - val_accuracy: 0.8298 - val_mae: 0.1810 - val_mse: 0.1572\n",
      "Epoch 56/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1298 - accuracy: 0.8438 - mae: 0.1858 - mse: 0.1298\n",
      "Epoch 00056: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1251 - accuracy: 0.8537 - mae: 0.1997 - mse: 0.1251 - val_loss: 0.1494 - val_accuracy: 0.8298 - val_mae: 0.2036 - val_mse: 0.1494\n",
      "Epoch 57/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1066 - accuracy: 0.8750 - mae: 0.1974 - mse: 0.1066\n",
      "Epoch 00057: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.1197 - accuracy: 0.8590 - mae: 0.2219 - mse: 0.1197 - val_loss: 0.1504 - val_accuracy: 0.8298 - val_mae: 0.2064 - val_mse: 0.1504\n",
      "Epoch 58/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0864 - accuracy: 0.9062 - mae: 0.1882 - mse: 0.0864\n",
      "Epoch 00058: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 74us/sample - loss: 0.1226 - accuracy: 0.8590 - mae: 0.2275 - mse: 0.1226 - val_loss: 0.1569 - val_accuracy: 0.8298 - val_mae: 0.1827 - val_mse: 0.1569\n",
      "Epoch 59/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1413 - accuracy: 0.8438 - mae: 0.1943 - mse: 0.1413\n",
      "Epoch 00059: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 72us/sample - loss: 0.1339 - accuracy: 0.8511 - mae: 0.2161 - mse: 0.1339 - val_loss: 0.1583 - val_accuracy: 0.8298 - val_mae: 0.1795 - val_mse: 0.1583\n",
      "Epoch 60/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1205 - accuracy: 0.8594 - mae: 0.1560 - mse: 0.1205\n",
      "Epoch 00060: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1270 - accuracy: 0.8590 - mae: 0.1958 - mse: 0.1270 - val_loss: 0.1520 - val_accuracy: 0.8298 - val_mae: 0.1945 - val_mse: 0.1520\n",
      "Epoch 61/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1427 - accuracy: 0.8438 - mae: 0.2195 - mse: 0.1427\n",
      "Epoch 00061: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.1209 - accuracy: 0.8564 - mae: 0.2211 - mse: 0.1209 - val_loss: 0.1450 - val_accuracy: 0.8298 - val_mae: 0.2329 - val_mse: 0.1450\n",
      "Epoch 62/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1172 - accuracy: 0.8594 - mae: 0.2480 - mse: 0.1172\n",
      "Epoch 00062: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1221 - accuracy: 0.8511 - mae: 0.2400 - mse: 0.1221 - val_loss: 0.1598 - val_accuracy: 0.8298 - val_mae: 0.1788 - val_mse: 0.1598\n",
      "Epoch 63/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1172 - accuracy: 0.8750 - mae: 0.1579 - mse: 0.1172\n",
      "Epoch 00063: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.1232 - accuracy: 0.8564 - mae: 0.1923 - mse: 0.1232 - val_loss: 0.1573 - val_accuracy: 0.8298 - val_mae: 0.3008 - val_mse: 0.1573\n",
      "Epoch 64/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1302 - accuracy: 0.8438 - mae: 0.2976 - mse: 0.1302\n",
      "Epoch 00064: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1209 - accuracy: 0.8564 - mae: 0.2151 - mse: 0.1209 - val_loss: 0.1726 - val_accuracy: 0.8298 - val_mae: 0.3370 - val_mse: 0.1726\n",
      "Epoch 65/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1534 - accuracy: 0.8438 - mae: 0.3451 - mse: 0.1534\n",
      "Epoch 00065: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.1308 - accuracy: 0.8564 - mae: 0.2110 - mse: 0.1308 - val_loss: 0.1537 - val_accuracy: 0.8298 - val_mae: 0.1912 - val_mse: 0.1537\n",
      "Epoch 66/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1336 - accuracy: 0.8438 - mae: 0.2097 - mse: 0.1336\n",
      "Epoch 00066: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 74us/sample - loss: 0.1199 - accuracy: 0.8564 - mae: 0.2166 - mse: 0.1199 - val_loss: 0.1506 - val_accuracy: 0.8298 - val_mae: 0.2800 - val_mse: 0.1506\n",
      "Epoch 67/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1321 - accuracy: 0.8281 - mae: 0.3055 - mse: 0.1321\n",
      "Epoch 00067: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1248 - accuracy: 0.8537 - mae: 0.2288 - mse: 0.1248 - val_loss: 0.1534 - val_accuracy: 0.8298 - val_mae: 0.1928 - val_mse: 0.1534\n",
      "Epoch 68/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1492 - accuracy: 0.8125 - mae: 0.2263 - mse: 0.1492\n",
      "Epoch 00068: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 72us/sample - loss: 0.1235 - accuracy: 0.8564 - mae: 0.2219 - mse: 0.1235 - val_loss: 0.1592 - val_accuracy: 0.8298 - val_mae: 0.1789 - val_mse: 0.1592\n",
      "Epoch 69/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1329 - accuracy: 0.8594 - mae: 0.1732 - mse: 0.1329\n",
      "Epoch 00069: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 82us/sample - loss: 0.1229 - accuracy: 0.8537 - mae: 0.1929 - mse: 0.1229 - val_loss: 0.1523 - val_accuracy: 0.8298 - val_mae: 0.2817 - val_mse: 0.1523\n",
      "Epoch 70/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1111 - accuracy: 0.8750 - mae: 0.2728 - mse: 0.1111\n",
      "Epoch 00070: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 69us/sample - loss: 0.1216 - accuracy: 0.8564 - mae: 0.2264 - mse: 0.1216 - val_loss: 0.1467 - val_accuracy: 0.8298 - val_mae: 0.2422 - val_mse: 0.1467\n",
      "Epoch 71/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1335 - accuracy: 0.8281 - mae: 0.2773 - mse: 0.1335\n",
      "Epoch 00071: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1312 - accuracy: 0.8484 - mae: 0.2307 - mse: 0.1312 - val_loss: 0.1583 - val_accuracy: 0.8298 - val_mae: 0.1806 - val_mse: 0.1583\n",
      "Epoch 72/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0754 - accuracy: 0.9219 - mae: 0.1183 - mse: 0.0754\n",
      "Epoch 00072: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 88us/sample - loss: 0.1227 - accuracy: 0.8564 - mae: 0.1897 - mse: 0.1227 - val_loss: 0.1444 - val_accuracy: 0.8298 - val_mae: 0.2378 - val_mse: 0.1444\n",
      "Epoch 73/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1914 - accuracy: 0.7344 - mae: 0.3360 - mse: 0.1914\n",
      "Epoch 00073: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1220 - accuracy: 0.8564 - mae: 0.2218 - mse: 0.1220 - val_loss: 0.1531 - val_accuracy: 0.8298 - val_mae: 0.1907 - val_mse: 0.1531\n",
      "Epoch 74/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1096 - accuracy: 0.8750 - mae: 0.1928 - mse: 0.1096\n",
      "Epoch 00074: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.1202 - accuracy: 0.8564 - mae: 0.2305 - mse: 0.1202 - val_loss: 0.1580 - val_accuracy: 0.8298 - val_mae: 0.1817 - val_mse: 0.1580\n",
      "Epoch 75/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0966 - accuracy: 0.8906 - mae: 0.1393 - mse: 0.0966\n",
      "Epoch 00075: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 72us/sample - loss: 0.1200 - accuracy: 0.8564 - mae: 0.2033 - mse: 0.1200 - val_loss: 0.1497 - val_accuracy: 0.8298 - val_mae: 0.2765 - val_mse: 0.1497\n",
      "Epoch 76/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1251 - accuracy: 0.8281 - mae: 0.2864 - mse: 0.1251\n",
      "Epoch 00076: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1161 - accuracy: 0.8590 - mae: 0.2338 - mse: 0.1161 - val_loss: 0.1539 - val_accuracy: 0.8298 - val_mae: 0.1923 - val_mse: 0.1539\n",
      "Epoch 77/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0898 - accuracy: 0.8750 - mae: 0.1600 - mse: 0.0898\n",
      "Epoch 00077: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 74us/sample - loss: 0.1174 - accuracy: 0.8590 - mae: 0.2266 - mse: 0.1174 - val_loss: 0.1531 - val_accuracy: 0.8298 - val_mae: 0.1957 - val_mse: 0.1531\n",
      "Epoch 78/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1003 - accuracy: 0.8750 - mae: 0.1781 - mse: 0.1003\n",
      "Epoch 00078: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.1225 - accuracy: 0.8564 - mae: 0.2268 - mse: 0.1225 - val_loss: 0.1600 - val_accuracy: 0.8298 - val_mae: 0.1780 - val_mse: 0.1600\n",
      "Epoch 79/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0954 - accuracy: 0.8906 - mae: 0.1414 - mse: 0.0954\n",
      "Epoch 00079: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 74us/sample - loss: 0.1244 - accuracy: 0.8564 - mae: 0.1931 - mse: 0.1244 - val_loss: 0.1461 - val_accuracy: 0.8298 - val_mae: 0.2371 - val_mse: 0.1461\n",
      "Epoch 80/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1110 - accuracy: 0.8750 - mae: 0.2438 - mse: 0.1110\n",
      "Epoch 00080: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.1264 - accuracy: 0.8537 - mae: 0.2395 - mse: 0.1264 - val_loss: 0.1605 - val_accuracy: 0.8298 - val_mae: 0.1775 - val_mse: 0.1605\n",
      "Epoch 81/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0940 - accuracy: 0.8906 - mae: 0.1311 - mse: 0.0940\n",
      "Epoch 00081: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.1265 - accuracy: 0.8564 - mae: 0.1829 - mse: 0.1265 - val_loss: 0.1536 - val_accuracy: 0.8298 - val_mae: 0.1926 - val_mse: 0.1536\n",
      "Epoch 82/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1126 - accuracy: 0.8594 - mae: 0.1965 - mse: 0.1126\n",
      "Epoch 00082: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.1177 - accuracy: 0.8590 - mae: 0.2283 - mse: 0.1177 - val_loss: 0.1549 - val_accuracy: 0.8298 - val_mae: 0.1918 - val_mse: 0.1549\n",
      "Epoch 83/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1024 - accuracy: 0.8750 - mae: 0.1773 - mse: 0.1024\n",
      "Epoch 00083: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 72us/sample - loss: 0.1209 - accuracy: 0.8564 - mae: 0.2156 - mse: 0.1209 - val_loss: 0.1475 - val_accuracy: 0.8298 - val_mae: 0.2414 - val_mse: 0.1475\n",
      "Epoch 84/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1164 - accuracy: 0.8438 - mae: 0.2466 - mse: 0.1164\n",
      "Epoch 00084: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1313 - accuracy: 0.8564 - mae: 0.2444 - mse: 0.1313 - val_loss: 0.1606 - val_accuracy: 0.8298 - val_mae: 0.1775 - val_mse: 0.1606\n",
      "Epoch 85/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1073 - accuracy: 0.8906 - mae: 0.1504 - mse: 0.1073\n",
      "Epoch 00085: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 80us/sample - loss: 0.1261 - accuracy: 0.8590 - mae: 0.1751 - mse: 0.1261 - val_loss: 0.1515 - val_accuracy: 0.8298 - val_mae: 0.1963 - val_mse: 0.1515\n",
      "Epoch 86/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1207 - accuracy: 0.8438 - mae: 0.2045 - mse: 0.1207\n",
      "Epoch 00086: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 85us/sample - loss: 0.1224 - accuracy: 0.8564 - mae: 0.2244 - mse: 0.1224 - val_loss: 0.1547 - val_accuracy: 0.8298 - val_mae: 0.1903 - val_mse: 0.1547\n",
      "Epoch 87/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0968 - accuracy: 0.8906 - mae: 0.1555 - mse: 0.0968\n",
      "Epoch 00087: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.1165 - accuracy: 0.8590 - mae: 0.2185 - mse: 0.1165 - val_loss: 0.1479 - val_accuracy: 0.8298 - val_mae: 0.2526 - val_mse: 0.1479\n",
      "Epoch 88/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1278 - accuracy: 0.8594 - mae: 0.2637 - mse: 0.1278\n",
      "Epoch 00088: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 74us/sample - loss: 0.1199 - accuracy: 0.8537 - mae: 0.2289 - mse: 0.1199 - val_loss: 0.1577 - val_accuracy: 0.8298 - val_mae: 0.1834 - val_mse: 0.1577\n",
      "Epoch 89/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1251 - accuracy: 0.8594 - mae: 0.1787 - mse: 0.1251\n",
      "Epoch 00089: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.1236 - accuracy: 0.8590 - mae: 0.2017 - mse: 0.1236 - val_loss: 0.1514 - val_accuracy: 0.8298 - val_mae: 0.2018 - val_mse: 0.1514\n",
      "Epoch 90/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0963 - accuracy: 0.8906 - mae: 0.1829 - mse: 0.0963\n",
      "Epoch 00090: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 72us/sample - loss: 0.1212 - accuracy: 0.8537 - mae: 0.2284 - mse: 0.1212 - val_loss: 0.1563 - val_accuracy: 0.8298 - val_mae: 0.1881 - val_mse: 0.1563\n",
      "Epoch 91/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.0881 - accuracy: 0.9062 - mae: 0.1408 - mse: 0.0881\n",
      "Epoch 00091: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.1191 - accuracy: 0.8564 - mae: 0.2061 - mse: 0.1191 - val_loss: 0.2219 - val_accuracy: 0.7234 - val_mae: 0.4116 - val_mse: 0.2219\n",
      "Epoch 92/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1786 - accuracy: 0.7344 - mae: 0.3660 - mse: 0.1786\n",
      "Epoch 00092: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 69us/sample - loss: 0.1265 - accuracy: 0.8457 - mae: 0.2087 - mse: 0.1265 - val_loss: 0.1488 - val_accuracy: 0.8298 - val_mae: 0.2095 - val_mse: 0.1488\n",
      "Epoch 93/200\n",
      " 64/376 [====>.........................] - ETA: 0s - loss: 0.1177 - accuracy: 0.8438 - mae: 0.2213 - mse: 0.1177\n",
      "Epoch 00093: val_loss did not improve from 0.14418\n",
      "376/376 [==============================] - 0s 77us/sample - loss: 0.1235 - accuracy: 0.8537 - mae: 0.2247 - mse: 0.1235 - val_loss: 0.1547 - val_accuracy: 0.8298 - val_mae: 0.1894 - val_mse: 0.1547\n",
      "Epoch 00093: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, \n",
    "                    validation_split = 0.2,\n",
    "                    #validation_data=(X, Y),\n",
    "                    epochs=200, \n",
    "                    batch_size=64,\n",
    "                    verbose=1,  # Verbosity mode. 0 = silent, 1 = progress bar(default), 2 = one line per epoch. \n",
    "                    callbacks=cp_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model_tf\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('./checkpoints_tf/my_checkpoint') # 수동으로 가중치 저장하기\n",
    "model.save('./saved_model_tf') # 전체 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 30)                540       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "470/470 - 0s - loss: 0.1272 - accuracy: 0.8532 - mae: 0.1907 - mse: 0.1272\n",
      "복원된 모델의 정확도: 85.32%\n",
      "(470, 1)\n"
     ]
    }
   ],
   "source": [
    "'''모델 전체 불러오기'''\n",
    "new_model = tf.keras.models.load_model('./saved_model_tf') # 전체 모델 불러오기\n",
    "\n",
    "# 모델 구조를 확인합니다\n",
    "new_model.summary()\n",
    "\n",
    "# 복원된 모델을 평가합니다\n",
    "loss, acc, mae, mse= new_model.evaluate(X,  Y, verbose=2)\n",
    "print('복원된 모델의 정확도: {:5.2f}%'.format(100*acc))\n",
    "\n",
    "print(new_model.predict(X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 - 0s - loss: 0.1255 - accuracy: 0.8511 - mae: 0.2470 - mse: 0.1255\n",
      "0.12551620374334618\n",
      "복원된 모델의 정확도: 85.11%\n",
      "(470, 1)\n"
     ]
    }
   ],
   "source": [
    "'''모델 weight 불러오기'''\n",
    "checkpoint_path = \"training_tf/cp-0043.ckpt\"\n",
    "# checkpoint_path = './checkpoints/my_checkpoint'\n",
    "model.load_weights(checkpoint_path) # \n",
    "\n",
    "loss, acc, mae, mse = model.evaluate(X, Y, verbose=2)\n",
    "print(loss)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "print(model.predict(X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
