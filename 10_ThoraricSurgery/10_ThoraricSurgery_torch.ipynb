{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 폐암 수술 환자의 생존율 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n",
      "    0   1     2     3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
      "0  293   1  3.80  2.80   0   0   0   0   0   0  12   0   0   0   1   0  62   0\n",
      "1    1   2  2.88  2.16   1   0   0   0   1   1  14   0   0   0   1   0  60   0\n",
      "2    8   2  3.19  2.50   1   0   0   0   1   0  11   0   0   1   1   0  66   1\n",
      "3   14   2  3.98  3.06   2   0   0   0   1   1  14   0   0   0   1   0  80   1\n",
      "4   17   2  2.21  1.88   0   0   1   0   0   0  12   0   0   0   1   0  56   0\n",
      "     0  1     2     3  4  5  6  7  8  9  10  11  12  13  14  15  16  class\n",
      "0  293  1  3.80  2.80  0  0  0  0  0  0  12   0   0   0   1   0  62      0\n",
      "1    1  2  2.88  2.16  1  0  0  0  1  1  14   0   0   0   1   0  60      0\n",
      "2    8  2  3.19  2.50  1  0  0  0  1  0  11   0   0   1   1   0  66      1\n",
      "3   14  2  3.98  3.06  2  0  0  0  1  1  14   0   0   0   1   0  80      1\n",
      "4   17  2  2.21  1.88  0  0  1  0  0  0  12   0   0   0   1   0  56      0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 필요한 라이브러리 불러옴\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n",
    "np.random.seed(3)\n",
    "torch.manual_seed(3)\n",
    "\n",
    "'''\n",
    "# 준비된 수술 환자 데이터를 불러옴\n",
    "Data_set = np.loadtxt(\"../dataset/ThoraricSurgery.csv\", delimiter=',')\n",
    "\n",
    "# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
    "X = Data_set[:, 0:17]\n",
    "Y = Data_set[:, 17]\n",
    "'''\n",
    "\n",
    "# 준비된 수술 환자 데이터를 불러옴 by using pandas\n",
    "#df = pd.read_csv(\"../dataset/ThoraricSurgery.csv\",\n",
    "#                      names=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"class\"])\n",
    "df = pd.read_csv(\"../dataset/ThoraricSurgery.csv\", header=None)\n",
    "print(df.head())\n",
    "df.rename(columns={17:\"class\"}, inplace=True)\n",
    "print(df.head())\n",
    "\n",
    "# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
    "X = df.drop(['class'], axis=1, inplace=False).values\n",
    "Y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.input_size = 17\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=self.input_size, out_features=30, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=30, out_features=1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=17, out_features=30, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device :\", device)\n",
    "epochs = 500\n",
    "batch_size = 64\n",
    "\n",
    "x = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "y = torch.from_numpy(Y).type(torch.LongTensor)\n",
    "\n",
    "dataset = TensorDataset(x, y)       \n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)  \n",
    "    \n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "#criterion = nn.BCEWithLogitsLoss() # Sigmoid + BCELoss\n",
    "\n",
    "#    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "#                                 lr=config.learning_rate, betas=(0.9, 0.98), eps=1e-09)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "        \n",
    "for epoch in range(epochs):\n",
    "    phase = 'train'\n",
    "    for k, [inputs, targets] in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(phase=='train'):\n",
    "            output = model(inputs)\n",
    "            \n",
    "            targets = targets.type_as(output)\n",
    "            loss = criterion(output, targets)\n",
    "            #print(loss)            \n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52393085],\n",
       "       [0.56837535],\n",
       "       [0.723369  ],\n",
       "       [0.6149242 ],\n",
       "       [0.51904935],\n",
       "       [0.5067892 ],\n",
       "       [0.5065459 ],\n",
       "       [0.54370856],\n",
       "       [0.5427494 ],\n",
       "       [0.5210081 ],\n",
       "       [0.5227097 ],\n",
       "       [0.5390689 ],\n",
       "       [0.52811724],\n",
       "       [0.52230406],\n",
       "       [0.6194684 ],\n",
       "       [0.53620976],\n",
       "       [0.5454474 ],\n",
       "       [0.5316139 ],\n",
       "       [0.5243564 ],\n",
       "       [0.54765254],\n",
       "       [0.5465744 ],\n",
       "       [0.56838787],\n",
       "       [0.6049236 ],\n",
       "       [0.5520054 ],\n",
       "       [0.5714037 ],\n",
       "       [0.53625304],\n",
       "       [0.6059196 ],\n",
       "       [0.53918016],\n",
       "       [0.5531917 ],\n",
       "       [0.5314384 ],\n",
       "       [0.5423662 ],\n",
       "       [0.5608119 ],\n",
       "       [0.59901   ],\n",
       "       [0.54690605],\n",
       "       [0.5802605 ],\n",
       "       [0.5064137 ],\n",
       "       [0.5294952 ],\n",
       "       [0.5615675 ],\n",
       "       [0.5422143 ],\n",
       "       [0.5455523 ],\n",
       "       [0.5443995 ],\n",
       "       [0.5609928 ],\n",
       "       [0.52973384],\n",
       "       [0.5408163 ],\n",
       "       [0.5268213 ],\n",
       "       [0.54343194],\n",
       "       [0.5338084 ],\n",
       "       [0.5376923 ],\n",
       "       [0.5563758 ],\n",
       "       [0.51150614],\n",
       "       [0.56391174],\n",
       "       [0.5404053 ],\n",
       "       [0.52785885],\n",
       "       [0.509841  ],\n",
       "       [0.5466295 ],\n",
       "       [0.5052152 ],\n",
       "       [0.72824585],\n",
       "       [0.5154847 ],\n",
       "       [0.6653563 ],\n",
       "       [0.6375326 ],\n",
       "       [0.5289057 ],\n",
       "       [0.5155217 ],\n",
       "       [0.51328856],\n",
       "       [0.5775707 ],\n",
       "       [0.53313196],\n",
       "       [0.52493733],\n",
       "       [0.5187345 ],\n",
       "       [0.5058221 ],\n",
       "       [0.52539104],\n",
       "       [0.51397717],\n",
       "       [0.5151206 ],\n",
       "       [0.53903246],\n",
       "       [0.54927117],\n",
       "       [0.6090722 ],\n",
       "       [0.6475987 ],\n",
       "       [0.5422783 ],\n",
       "       [0.53649265],\n",
       "       [0.54127216],\n",
       "       [0.5299651 ],\n",
       "       [0.549574  ],\n",
       "       [0.5452506 ],\n",
       "       [0.5656182 ],\n",
       "       [0.5486092 ],\n",
       "       [0.6096689 ],\n",
       "       [0.54295945],\n",
       "       [0.54266316],\n",
       "       [0.54866236],\n",
       "       [0.5700233 ],\n",
       "       [0.5139309 ],\n",
       "       [0.51546186],\n",
       "       [0.5330697 ],\n",
       "       [0.6035908 ],\n",
       "       [0.53692526],\n",
       "       [0.59919333],\n",
       "       [0.6546306 ],\n",
       "       [0.52097553],\n",
       "       [0.53965414],\n",
       "       [0.53879285],\n",
       "       [0.5193171 ],\n",
       "       [0.53114176],\n",
       "       [0.529896  ],\n",
       "       [0.5527992 ],\n",
       "       [0.53702754],\n",
       "       [0.5369588 ],\n",
       "       [0.5323308 ],\n",
       "       [0.5354376 ],\n",
       "       [0.5191473 ],\n",
       "       [0.5345239 ],\n",
       "       [0.58325917],\n",
       "       [0.54810596],\n",
       "       [0.53341746],\n",
       "       [0.56471246],\n",
       "       [0.50708157],\n",
       "       [0.5391605 ],\n",
       "       [0.55884385],\n",
       "       [0.53463674],\n",
       "       [0.5424382 ],\n",
       "       [0.53801054],\n",
       "       [0.5404609 ],\n",
       "       [0.5533417 ],\n",
       "       [0.54880375],\n",
       "       [0.50169575],\n",
       "       [0.52242184],\n",
       "       [0.5399591 ],\n",
       "       [0.5210807 ],\n",
       "       [0.5166391 ],\n",
       "       [0.5359394 ],\n",
       "       [0.525729  ],\n",
       "       [0.620282  ],\n",
       "       [0.5212627 ],\n",
       "       [0.5815719 ],\n",
       "       [0.50522935],\n",
       "       [0.5458572 ],\n",
       "       [0.5623315 ],\n",
       "       [0.547108  ],\n",
       "       [0.51605046],\n",
       "       [0.55121005],\n",
       "       [0.5787157 ],\n",
       "       [0.544841  ],\n",
       "       [0.52582085],\n",
       "       [0.53179026],\n",
       "       [0.60840404],\n",
       "       [0.5423496 ],\n",
       "       [0.52346486],\n",
       "       [0.5317034 ],\n",
       "       [0.53946996],\n",
       "       [0.5282853 ],\n",
       "       [0.6446547 ],\n",
       "       [0.5357637 ],\n",
       "       [0.5462409 ],\n",
       "       [0.52883554],\n",
       "       [0.5422572 ],\n",
       "       [0.58666307],\n",
       "       [0.55824846],\n",
       "       [0.5398895 ],\n",
       "       [0.5349353 ],\n",
       "       [0.52296066],\n",
       "       [0.5340766 ],\n",
       "       [0.51819223],\n",
       "       [0.53924507],\n",
       "       [0.52617323],\n",
       "       [0.5275786 ],\n",
       "       [0.5372972 ],\n",
       "       [0.54425955],\n",
       "       [0.54395586],\n",
       "       [0.5318866 ],\n",
       "       [0.532086  ],\n",
       "       [0.57146513],\n",
       "       [0.59853876],\n",
       "       [0.5130827 ],\n",
       "       [0.57071006],\n",
       "       [0.55910885],\n",
       "       [0.51911944],\n",
       "       [0.5439612 ],\n",
       "       [0.60473543],\n",
       "       [0.6497772 ],\n",
       "       [0.5410233 ],\n",
       "       [0.6001103 ],\n",
       "       [0.6389197 ],\n",
       "       [0.53268105],\n",
       "       [0.563201  ],\n",
       "       [0.58739054],\n",
       "       [0.58197784],\n",
       "       [0.5681636 ],\n",
       "       [0.55282223],\n",
       "       [0.5868716 ],\n",
       "       [0.5678073 ],\n",
       "       [0.55742526],\n",
       "       [0.53028446],\n",
       "       [0.5413477 ],\n",
       "       [0.56033254],\n",
       "       [0.54234916],\n",
       "       [0.54161274],\n",
       "       [0.5429952 ],\n",
       "       [0.51051253],\n",
       "       [0.54702854],\n",
       "       [0.5447247 ],\n",
       "       [0.54218864],\n",
       "       [0.5747532 ],\n",
       "       [0.5903423 ],\n",
       "       [0.5468468 ],\n",
       "       [0.52263284],\n",
       "       [0.575612  ],\n",
       "       [0.5584256 ],\n",
       "       [0.51753855],\n",
       "       [0.55220604],\n",
       "       [0.53861904],\n",
       "       [0.55203277],\n",
       "       [0.52350193],\n",
       "       [0.5305951 ],\n",
       "       [0.55909586],\n",
       "       [0.6678816 ],\n",
       "       [0.60765713],\n",
       "       [0.5543796 ],\n",
       "       [0.52127343],\n",
       "       [0.53038263],\n",
       "       [0.5380331 ],\n",
       "       [0.61239445],\n",
       "       [0.5299887 ],\n",
       "       [0.547633  ],\n",
       "       [0.57565695],\n",
       "       [0.5650172 ],\n",
       "       [0.54051924],\n",
       "       [0.6131077 ],\n",
       "       [0.6110657 ],\n",
       "       [0.55547255],\n",
       "       [0.5721046 ],\n",
       "       [0.5810973 ],\n",
       "       [0.5430996 ],\n",
       "       [0.55703324],\n",
       "       [0.5460221 ],\n",
       "       [0.55543715],\n",
       "       [0.522091  ],\n",
       "       [0.5302912 ],\n",
       "       [0.53473556],\n",
       "       [0.50803065],\n",
       "       [0.53643036],\n",
       "       [0.54964113],\n",
       "       [0.55398566],\n",
       "       [0.5439285 ],\n",
       "       [0.55636954],\n",
       "       [0.5467705 ],\n",
       "       [0.5493118 ],\n",
       "       [0.55756265],\n",
       "       [0.51948154],\n",
       "       [0.5649668 ],\n",
       "       [0.5477324 ],\n",
       "       [0.5537363 ],\n",
       "       [0.54123294],\n",
       "       [0.5379982 ],\n",
       "       [0.5687507 ],\n",
       "       [0.56429493],\n",
       "       [0.5590758 ],\n",
       "       [0.5440643 ],\n",
       "       [0.5396479 ],\n",
       "       [0.5798526 ],\n",
       "       [0.65285766],\n",
       "       [0.55521053],\n",
       "       [0.58413666],\n",
       "       [0.5367223 ],\n",
       "       [0.5850304 ],\n",
       "       [0.5529647 ],\n",
       "       [0.5941335 ],\n",
       "       [0.5266002 ],\n",
       "       [0.5490705 ],\n",
       "       [0.56725395],\n",
       "       [0.52335083],\n",
       "       [0.5623896 ],\n",
       "       [0.54896075],\n",
       "       [0.55275327],\n",
       "       [0.55519813],\n",
       "       [0.5958673 ],\n",
       "       [0.5404155 ],\n",
       "       [0.55928576],\n",
       "       [0.6159308 ],\n",
       "       [0.5310741 ],\n",
       "       [0.5438567 ],\n",
       "       [0.56888086],\n",
       "       [0.64617187],\n",
       "       [0.5481978 ],\n",
       "       [0.54048526],\n",
       "       [0.5617977 ],\n",
       "       [0.53052956],\n",
       "       [0.57622087],\n",
       "       [0.55792505],\n",
       "       [0.5220996 ],\n",
       "       [0.55142844],\n",
       "       [0.5592726 ],\n",
       "       [0.5595171 ],\n",
       "       [0.55974144],\n",
       "       [0.57941663],\n",
       "       [0.5839492 ],\n",
       "       [0.5521312 ],\n",
       "       [0.5375751 ],\n",
       "       [0.6142247 ],\n",
       "       [0.5548309 ],\n",
       "       [0.50322133],\n",
       "       [0.5391994 ],\n",
       "       [0.5240441 ],\n",
       "       [0.5491871 ],\n",
       "       [0.5602129 ],\n",
       "       [0.5767357 ],\n",
       "       [0.5694661 ],\n",
       "       [0.52770853],\n",
       "       [0.54137486],\n",
       "       [0.5535674 ],\n",
       "       [0.5838821 ],\n",
       "       [0.5243474 ],\n",
       "       [0.5533663 ],\n",
       "       [0.52401644],\n",
       "       [0.5388123 ],\n",
       "       [0.57162195],\n",
       "       [0.5382586 ],\n",
       "       [0.56407034],\n",
       "       [0.5489011 ],\n",
       "       [0.5426152 ],\n",
       "       [0.50350046],\n",
       "       [0.5031866 ],\n",
       "       [0.53104466],\n",
       "       [0.5425173 ],\n",
       "       [0.62732196],\n",
       "       [0.5419561 ],\n",
       "       [0.55408615],\n",
       "       [0.5578865 ],\n",
       "       [0.55530936],\n",
       "       [0.63521135],\n",
       "       [0.56513673],\n",
       "       [0.5854724 ],\n",
       "       [0.5433389 ],\n",
       "       [0.54834706],\n",
       "       [0.5275692 ],\n",
       "       [0.53729784],\n",
       "       [0.5364581 ],\n",
       "       [0.5556029 ],\n",
       "       [0.6316894 ],\n",
       "       [0.5471659 ],\n",
       "       [0.5161798 ],\n",
       "       [0.5330197 ],\n",
       "       [0.54145336],\n",
       "       [0.5337364 ],\n",
       "       [0.53968626],\n",
       "       [0.5200054 ],\n",
       "       [0.5449851 ],\n",
       "       [0.5470023 ],\n",
       "       [0.59091216],\n",
       "       [0.612386  ],\n",
       "       [0.55689406],\n",
       "       [0.5363715 ],\n",
       "       [0.5356074 ],\n",
       "       [0.55240965],\n",
       "       [0.5282162 ],\n",
       "       [0.5425977 ],\n",
       "       [0.5280118 ],\n",
       "       [0.5179036 ],\n",
       "       [0.55029094],\n",
       "       [0.53980136],\n",
       "       [0.53764737],\n",
       "       [0.5915223 ],\n",
       "       [0.53363407],\n",
       "       [0.55018353],\n",
       "       [0.52225286],\n",
       "       [0.5589744 ],\n",
       "       [0.51934403],\n",
       "       [0.59071124],\n",
       "       [0.51781017],\n",
       "       [0.528704  ],\n",
       "       [0.5187044 ],\n",
       "       [0.54796153],\n",
       "       [0.5559738 ],\n",
       "       [0.54010016],\n",
       "       [0.56192577],\n",
       "       [0.5759525 ],\n",
       "       [0.52274305],\n",
       "       [0.56124043],\n",
       "       [0.55471677],\n",
       "       [0.5467835 ],\n",
       "       [0.5398228 ],\n",
       "       [0.542341  ],\n",
       "       [0.57974255],\n",
       "       [0.54115266],\n",
       "       [0.56977236],\n",
       "       [0.5578019 ],\n",
       "       [0.52543336],\n",
       "       [0.50029534],\n",
       "       [0.5293075 ],\n",
       "       [0.5254485 ],\n",
       "       [0.5478191 ],\n",
       "       [0.5431813 ],\n",
       "       [0.5635475 ],\n",
       "       [0.5529587 ],\n",
       "       [0.52037674],\n",
       "       [0.547425  ],\n",
       "       [0.5229451 ],\n",
       "       [0.52923775],\n",
       "       [0.518462  ],\n",
       "       [0.5623403 ],\n",
       "       [0.5501186 ],\n",
       "       [0.5474785 ],\n",
       "       [0.5197407 ],\n",
       "       [0.53675604],\n",
       "       [0.5582051 ],\n",
       "       [0.5190762 ],\n",
       "       [0.52007514],\n",
       "       [0.54601216],\n",
       "       [0.55646324],\n",
       "       [0.5239753 ],\n",
       "       [0.6195593 ],\n",
       "       [0.5215298 ],\n",
       "       [0.5281538 ],\n",
       "       [0.538059  ],\n",
       "       [0.51921463],\n",
       "       [0.6398529 ],\n",
       "       [0.5519938 ],\n",
       "       [0.53992915],\n",
       "       [0.5327088 ],\n",
       "       [0.5630266 ],\n",
       "       [0.5472113 ],\n",
       "       [0.55510646],\n",
       "       [0.5310055 ],\n",
       "       [0.56420535],\n",
       "       [0.5408815 ],\n",
       "       [0.64905924],\n",
       "       [0.52181166],\n",
       "       [0.54402024],\n",
       "       [0.5303142 ],\n",
       "       [0.6248926 ],\n",
       "       [0.54094493],\n",
       "       [0.5279257 ],\n",
       "       [0.56686026],\n",
       "       [0.5221732 ],\n",
       "       [0.5037936 ],\n",
       "       [0.53391683],\n",
       "       [0.5338443 ],\n",
       "       [0.5472615 ],\n",
       "       [0.5534832 ],\n",
       "       [0.50208163],\n",
       "       [0.53213817],\n",
       "       [0.5430638 ],\n",
       "       [0.5616228 ],\n",
       "       [0.5280452 ],\n",
       "       [0.54226863],\n",
       "       [0.57550234],\n",
       "       [0.58564764],\n",
       "       [0.5708778 ],\n",
       "       [0.5649318 ],\n",
       "       [0.545843  ],\n",
       "       [0.5405886 ],\n",
       "       [0.5225384 ],\n",
       "       [0.6221228 ],\n",
       "       [0.50119346],\n",
       "       [0.5838028 ],\n",
       "       [0.6179283 ],\n",
       "       [0.64592904],\n",
       "       [0.5755867 ],\n",
       "       [0.52919513],\n",
       "       [0.5583047 ],\n",
       "       [0.59481794],\n",
       "       [0.5859599 ],\n",
       "       [0.5866642 ],\n",
       "       [0.5459261 ],\n",
       "       [0.5845014 ],\n",
       "       [0.59710824],\n",
       "       [0.5278928 ],\n",
       "       [0.5007096 ],\n",
       "       [0.5831756 ],\n",
       "       [0.5394197 ],\n",
       "       [0.5443238 ],\n",
       "       [0.5258081 ],\n",
       "       [0.6040649 ],\n",
       "       [0.5296651 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model(x)\n",
    "#prediction = torch.sigmoid(prediction)\n",
    "prediction.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
